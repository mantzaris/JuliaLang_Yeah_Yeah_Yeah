{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Zygote\n",
    "\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">write a function and make a function for the gradient of the function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d2f1 (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(x) = 3x^2 - 2x + 10 # the function\n",
    "df1(x) = gradient(f1, x)[1] # the gradient function df/dx = 6x - 2\n",
    "d2f1(x) = gradient(df1, x)[1] # acceleration d²f/dx² = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad1 = 58.0, grads2 = [4.0, 10.0, 58.0], accelerations = [6.0, 6.0, 6.0]\n"
     ]
    }
   ],
   "source": [
    "grad1 = df1(10) # gradient at 1 point\n",
    "grads2 = df1.([1,2,10]) #gradient at multiple points\n",
    "accelerations = d2f1.([1,2,10])\n",
    "println(\"grad1 = $(grad1), grads2 = $(grads2), accelerations = $(accelerations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">We can find the gradient of a function with various computations inside and especially the well known MSE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_mse (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mse(x, y) = sum((x .- y).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads = ([0.0, 2.0, -2.0], [-0.0, -2.0, 2.0])\n"
     ]
    }
   ],
   "source": [
    "xx = [2,1,0]\n",
    "yy = [2,0,1]\n",
    "grads = gradient(f_mse, xx, yy)\n",
    "println(\"grads = $(grads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = [2,1,0]\n",
    "yy = [2,0,1]\n",
    "gs = gradient(Flux.params(xx, yy)) do\n",
    "         f_mse(xx, yy)\n",
    "        end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:grads, :params)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IdDict{Any, Any} with 4 entries:\n",
       "  [2, 0, 1]  => [-0.0, -2.0, 2.0]\n",
       "  :(Main.xx) => [0.0, 2.0, -2.0]\n",
       "  [2, 1, 0]  => [0.0, 2.0, -2.0]\n",
       "  :(Main.yy) => [-0.0, -2.0, 2.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[2, 1, 0], [2, 0, 1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       "  0.0\n",
       "  2.0\n",
       " -2.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " -0.0\n",
       " -2.0\n",
       "  2.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">linear regression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6413084651379"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = rand(5), rand(2) # 5 features (dims) -> 2 featuers (dims)\n",
    "W = rand(2, 5)\n",
    "b = rand(2)\n",
    "m1(x) = W*x .+ b\n",
    "function loss1(x, y)\n",
    "    y_hat = m1(x)\n",
    "    sum((y .- y_hat).^2)\n",
    "end\n",
    "loss1(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = gradient(() -> loss1(x, y), Flux.params(W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Float64}:\n",
       " 1.11801  0.738165  0.497641  0.293601  1.86301\n",
       " 1.37459  0.90757   0.611847  0.360981  2.29057"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 2.050970584123454\n",
       " 2.521656900454917"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Float64}:\n",
       " 1.11801  0.738165  0.497641  0.293601  1.86301\n",
       " 1.37459  0.90757   0.611847  0.360981  2.29057"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_grad = gs[W]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Update parameter **W** (the transformation matrix) by a step</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Float64}:\n",
       " 0.368965   0.541657   0.773674  0.337563  -0.02013\n",
       " 0.823958  -0.0434863  0.16209   0.198202  -0.0327843"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = W .- (0.1 .* W_grad )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4221196010200685"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">And another step in that direction</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773611424017321"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = W .- (0.1 .* W_grad )\n",
    "loss1(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">And another step</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10703308928289071"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = W .- (0.1 .* W_grad )\n",
    "loss1(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">And another step</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011135441663544512"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = W .- (0.1 .* W_grad )\n",
    "loss1(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Layers (sequential transformations)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.9995948052567933\n",
       " 1.7037513960875303"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = rand(3, 5) #5 to 3 transformation\n",
    "b1 = rand(3)\n",
    "layer1(x) = W1 * x .+ b1\n",
    "\n",
    "W2 = rand(2, 3) #3 to 2 transformation\n",
    "b2 = rand(2)\n",
    "layer2(x) = W2 * x .+ b2\n",
    "\n",
    "m2(x) = layer2(sigmoid.(layer1(x)))\n",
    "\n",
    "m2(rand(5)) #transforming 5 to 3, then 3 to 2 dims with an activation layer of sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss2 (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = rand(5), rand(2)\n",
    "function loss2(x, y)\n",
    "    y_hat = m2(x)\n",
    "    sum((y .- y_hat).^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = gradient(() -> loss2(x, y), Flux.params(W1, b1, W2, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×5 Matrix{Float64}:\n",
       " 0.0858024  0.316283  0.437786  0.141176   0.0700564\n",
       " 0.033757   0.124434  0.172237  0.0555424  0.0275621\n",
       " 0.0711572  0.262298  0.363063  0.117079   0.0580988"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[W1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Float64}:\n",
       " 2.98021  2.9593   2.8915\n",
       " 1.74865  1.73638  1.69659"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[W2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.260343925485792"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Float64}:\n",
       " 2.98021  2.9593   2.8915\n",
       " 1.74865  1.73638  1.69659"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1_grad = gs[W1]\n",
    "W2_grad = gs[W2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Float64}:\n",
       " 0.670774   -0.0277169  0.118853\n",
       " 0.0157749   0.073581   0.500474"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = W1 .- (0.1 .* W1_grad ) \n",
    "W2 = W2 .- (0.1 .* W2_grad ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4628725867177643"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Float64}:\n",
       "  0.372753  -0.323647  -0.170297\n",
       " -0.15909   -0.100057   0.330814"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = W1 .- (0.1 .* W1_grad ) \n",
    "W2 = W2 .- (0.1 .* W2_grad ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13576939432941476"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Look at a simple function to 'fit'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_function (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function target_function(x)\n",
    "    4x + 2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">training and testing data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0 1 … 4 5], [6 7 … 9 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = hcat(0:5...), hcat(6:10...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2 6 … 18 22], [26 30 … 38 42])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = target_function.(x_train), target_function.(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip140\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip140)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip141\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip140)\" d=\"\n",
       "M140.696 1486.45 L2352.76 1486.45 L2352.76 47.2441 L140.696 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip142\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  203.301,1486.45 203.301,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  620.671,1486.45 620.671,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1038.04,1486.45 1038.04,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1455.41,1486.45 1455.41,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1872.78,1486.45 1872.78,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2290.15,1486.45 2290.15,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.301,1486.45 203.301,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  620.671,1486.45 620.671,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1038.04,1486.45 1038.04,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1455.41,1486.45 1455.41,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1872.78,1486.45 1872.78,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2290.15,1486.45 2290.15,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip140)\" d=\"M203.301 1517.37 Q199.69 1517.37 197.861 1520.93 Q196.056 1524.47 196.056 1531.6 Q196.056 1538.71 197.861 1542.27 Q199.69 1545.82 203.301 1545.82 Q206.935 1545.82 208.741 1542.27 Q210.57 1538.71 210.57 1531.6 Q210.57 1524.47 208.741 1520.93 Q206.935 1517.37 203.301 1517.37 M203.301 1513.66 Q209.111 1513.66 212.167 1518.27 Q215.245 1522.85 215.245 1531.6 Q215.245 1540.33 212.167 1544.94 Q209.111 1549.52 203.301 1549.52 Q197.491 1549.52 194.412 1544.94 Q191.357 1540.33 191.357 1531.6 Q191.357 1522.85 194.412 1518.27 Q197.491 1513.66 203.301 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M611.053 1544.91 L618.692 1544.91 L618.692 1518.55 L610.382 1520.21 L610.382 1515.95 L618.645 1514.29 L623.321 1514.29 L623.321 1544.91 L630.96 1544.91 L630.96 1548.85 L611.053 1548.85 L611.053 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M1032.69 1544.91 L1049.01 1544.91 L1049.01 1548.85 L1027.07 1548.85 L1027.07 1544.91 Q1029.73 1542.16 1034.31 1537.53 Q1038.92 1532.88 1040.1 1531.53 Q1042.35 1529.01 1043.23 1527.27 Q1044.13 1525.51 1044.13 1523.82 Q1044.13 1521.07 1042.18 1519.33 Q1040.26 1517.6 1037.16 1517.6 Q1034.96 1517.6 1032.51 1518.36 Q1030.08 1519.13 1027.3 1520.68 L1027.3 1515.95 Q1030.12 1514.82 1032.58 1514.24 Q1035.03 1513.66 1037.07 1513.66 Q1042.44 1513.66 1045.63 1516.35 Q1048.83 1519.03 1048.83 1523.52 Q1048.83 1525.65 1048.02 1527.57 Q1047.23 1529.47 1045.12 1532.07 Q1044.55 1532.74 1041.44 1535.95 Q1038.34 1539.15 1032.69 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M1459.66 1530.21 Q1463.01 1530.93 1464.89 1533.2 Q1466.79 1535.47 1466.79 1538.8 Q1466.79 1543.92 1463.27 1546.72 Q1459.75 1549.52 1453.27 1549.52 Q1451.09 1549.52 1448.78 1549.08 Q1446.49 1548.66 1444.03 1547.81 L1444.03 1543.29 Q1445.98 1544.43 1448.29 1545.01 Q1450.61 1545.58 1453.13 1545.58 Q1457.53 1545.58 1459.82 1543.85 Q1462.14 1542.11 1462.14 1538.8 Q1462.14 1535.75 1459.98 1534.03 Q1457.85 1532.3 1454.03 1532.3 L1450.01 1532.3 L1450.01 1528.45 L1454.22 1528.45 Q1457.67 1528.45 1459.5 1527.09 Q1461.32 1525.7 1461.32 1523.11 Q1461.32 1520.45 1459.43 1519.03 Q1457.55 1517.6 1454.03 1517.6 Q1452.11 1517.6 1449.91 1518.01 Q1447.71 1518.43 1445.08 1519.31 L1445.08 1515.14 Q1447.74 1514.4 1450.05 1514.03 Q1452.39 1513.66 1454.45 1513.66 Q1459.77 1513.66 1462.88 1516.09 Q1465.98 1518.5 1465.98 1522.62 Q1465.98 1525.49 1464.33 1527.48 Q1462.69 1529.45 1459.66 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M1875.79 1518.36 L1863.98 1536.81 L1875.79 1536.81 L1875.79 1518.36 M1874.56 1514.29 L1880.44 1514.29 L1880.44 1536.81 L1885.37 1536.81 L1885.37 1540.7 L1880.44 1540.7 L1880.44 1548.85 L1875.79 1548.85 L1875.79 1540.7 L1860.19 1540.7 L1860.19 1536.19 L1874.56 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M2280.43 1514.29 L2298.78 1514.29 L2298.78 1518.22 L2284.71 1518.22 L2284.71 1526.7 Q2285.73 1526.35 2286.75 1526.19 Q2287.77 1526 2288.78 1526 Q2294.57 1526 2297.95 1529.17 Q2301.33 1532.34 2301.33 1537.76 Q2301.33 1543.34 2297.86 1546.44 Q2294.39 1549.52 2288.07 1549.52 Q2285.89 1549.52 2283.62 1549.15 Q2281.38 1548.78 2278.97 1548.04 L2278.97 1543.34 Q2281.05 1544.47 2283.28 1545.03 Q2285.5 1545.58 2287.97 1545.58 Q2291.98 1545.58 2294.32 1543.48 Q2296.66 1541.37 2296.66 1537.76 Q2296.66 1534.15 2294.32 1532.04 Q2291.98 1529.94 2287.97 1529.94 Q2286.1 1529.94 2284.22 1530.35 Q2282.37 1530.77 2280.43 1531.65 L2280.43 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1242.05 2352.76,1242.05 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,902.62 2352.76,902.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,563.185 2352.76,563.185 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip142)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,223.75 2352.76,223.75 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 140.696,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1242.05 159.593,1242.05 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,902.62 159.593,902.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,563.185 159.593,563.185 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip140)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,223.75 159.593,223.75 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip140)\" d=\"M83.7929 1224.77 L102.149 1224.77 L102.149 1228.71 L88.0753 1228.71 L88.0753 1237.18 Q89.0938 1236.83 90.1123 1236.67 Q91.1308 1236.49 92.1493 1236.49 Q97.9363 1236.49 101.316 1239.66 Q104.696 1242.83 104.696 1248.25 Q104.696 1253.83 101.223 1256.93 Q97.7511 1260.01 91.4317 1260.01 Q89.2558 1260.01 86.9873 1259.64 Q84.7419 1259.27 82.3346 1258.52 L82.3346 1253.83 Q84.4179 1254.96 86.6401 1255.52 Q88.8623 1256.07 91.3391 1256.07 Q95.3437 1256.07 97.6817 1253.96 Q100.02 1251.86 100.02 1248.25 Q100.02 1244.64 97.6817 1242.53 Q95.3437 1240.42 91.3391 1240.42 Q89.4641 1240.42 87.5892 1240.84 Q85.7373 1241.26 83.7929 1242.14 L83.7929 1224.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M53.3995 915.965 L61.0384 915.965 L61.0384 889.599 L52.7282 891.266 L52.7282 887.007 L60.9921 885.34 L65.668 885.34 L65.668 915.965 L73.3068 915.965 L73.3068 919.9 L53.3995 919.9 L53.3995 915.965 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M92.7512 888.419 Q89.1401 888.419 87.3114 891.983 Q85.5058 895.525 85.5058 902.655 Q85.5058 909.761 87.3114 913.326 Q89.1401 916.868 92.7512 916.868 Q96.3854 916.868 98.1909 913.326 Q100.02 909.761 100.02 902.655 Q100.02 895.525 98.1909 891.983 Q96.3854 888.419 92.7512 888.419 M92.7512 884.715 Q98.5613 884.715 101.617 889.321 Q104.696 893.905 104.696 902.655 Q104.696 911.381 101.617 915.988 Q98.5613 920.571 92.7512 920.571 Q86.941 920.571 83.8623 915.988 Q80.8068 911.381 80.8068 902.655 Q80.8068 893.905 83.8623 889.321 Q86.941 884.715 92.7512 884.715 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M54.3949 576.53 L62.0337 576.53 L62.0337 550.164 L53.7236 551.831 L53.7236 547.572 L61.9874 545.905 L66.6633 545.905 L66.6633 576.53 L74.3022 576.53 L74.3022 580.465 L54.3949 580.465 L54.3949 576.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M83.7929 545.905 L102.149 545.905 L102.149 549.84 L88.0753 549.84 L88.0753 558.312 Q89.0938 557.965 90.1123 557.803 Q91.1308 557.618 92.1493 557.618 Q97.9363 557.618 101.316 560.789 Q104.696 563.961 104.696 569.377 Q104.696 574.956 101.223 578.058 Q97.7511 581.136 91.4317 581.136 Q89.2558 581.136 86.9873 580.766 Q84.7419 580.396 82.3346 579.655 L82.3346 574.956 Q84.4179 576.09 86.6401 576.646 Q88.8623 577.201 91.3391 577.201 Q95.3437 577.201 97.6817 575.095 Q100.02 572.988 100.02 569.377 Q100.02 565.766 97.6817 563.66 Q95.3437 561.553 91.3391 561.553 Q89.4641 561.553 87.5892 561.97 Q85.7373 562.386 83.7929 563.266 L83.7929 545.905 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M56.6171 237.095 L72.9365 237.095 L72.9365 241.03 L50.9921 241.03 L50.9921 237.095 Q53.6541 234.34 58.2375 229.711 Q62.8439 225.058 64.0245 223.715 Q66.2698 221.192 67.1494 219.456 Q68.0522 217.697 68.0522 216.007 Q68.0522 213.253 66.1078 211.516 Q64.1865 209.78 61.0847 209.78 Q58.8856 209.78 56.4319 210.544 Q54.0014 211.308 51.2236 212.859 L51.2236 208.137 Q54.0477 207.003 56.5014 206.424 Q58.955 205.845 60.9921 205.845 Q66.3624 205.845 69.5568 208.53 Q72.7513 211.216 72.7513 215.706 Q72.7513 217.836 71.9411 219.757 Q71.1541 221.655 69.0476 224.248 Q68.4689 224.919 65.367 228.137 Q62.2652 231.331 56.6171 237.095 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip140)\" d=\"M92.7512 209.549 Q89.1401 209.549 87.3114 213.114 Q85.5058 216.655 85.5058 223.785 Q85.5058 230.891 87.3114 234.456 Q89.1401 237.998 92.7512 237.998 Q96.3854 237.998 98.1909 234.456 Q100.02 230.891 100.02 223.785 Q100.02 216.655 98.1909 213.114 Q96.3854 209.549 92.7512 209.549 M92.7512 205.845 Q98.5613 205.845 101.617 210.452 Q104.696 215.035 104.696 223.785 Q104.696 232.512 101.617 237.118 Q98.5613 241.702 92.7512 241.702 Q86.941 241.702 83.8623 237.118 Q80.8068 232.512 80.8068 223.785 Q80.8068 215.035 83.8623 210.452 Q86.941 205.845 92.7512 205.845 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip142)\" cx=\"203.301\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip142)\" cx=\"620.671\" cy=\"1174.17\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip142)\" cx=\"1038.04\" cy=\"902.62\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip142)\" cx=\"1455.41\" cy=\"631.072\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip142)\" cx=\"1872.78\" cy=\"359.524\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip142)\" cx=\"2290.15\" cy=\"87.9763\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(x_train, y_train, legend=false, linetype=\"scatter\", color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">The Single Neuron Model</span>\n",
    "**supervised learning**\n",
    "\n",
    "Labeled data, D = $\\{(x_1,y_2),(x_2,y_2),\\ldots,(x_n,y_n)\\}$\n",
    "\n",
    "Each data point can be considered to be a 'signal' (common in the journal publications to see the data points referred to as) x_i\n",
    "\n",
    "$x_i + 1 \\rightarrow (w_1,b) \\rightarrow z = w_1 * x_i + b \\rightarrow a = \\phi(z) $\n",
    "\n",
    "Here $z$ can be considered to be a 'pre-activation' and $a$ a post-activation, that exists within the neuron. That is within the single neuron there are 2 steps, the production of $z$ that is a linear 'projection'/'transformation' and the $a$ is the 'activation' that is typically non-linear (eg. sigmoid or rectified linear units 'relu')\n",
    "\n",
    "There is a 'cost' function for the neuron, in a manner similar to that of the common statistical fits\n",
    "\n",
    "$C(w,b) = \\sum_{i=1}^N dist(y,\\hat{y}_i)$\n",
    "\n",
    "The cost function gives us a 'landscape' (hyperdimensional surface of $y$ and $\\hat{y}$ similarity for the parameters of the model) to minimize the cost (degree of fit). Our goal is to find $W$ and $b$ which minimizes $C$. The cost function can from a variety of forms based upon the 'dist' function where in regression cases it is often mean squared error, and in categorical predictions cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Produce a dense layer of 1 element, a 1 to 1 transformation</span>\n",
    "\n",
    "The Dense function produces a **dense** layer of connections between the neurons (input dimensions). The first argument is the input dimension (input feature size) and the second value is the output dimension (output layer feature size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1 => 1)       \u001b[90m# 2 parameters\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dense(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:weight, :bias, :σ)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float32}:\n",
       " 1.5517563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float32}:\n",
       " 0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identity (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">See what the random untrained model parameters produce for the model outputs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Matrix{Float32}:\n",
       " 0.0  1.55176  3.10351  4.65527  6.20703  7.75878"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x,y) = Flux.mse(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Current loss of the model and its randomly initialized parameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.42649f0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Define an optimizer to change the parameters according the loss function</span>\n",
    "\n",
    "The step size is the $\\eta$ argument/parameter value\n",
    "\n",
    "there is also the popular alternative of **ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Flux.Descent(0.05) #non-stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">package the data into 'tuples' that makes it easy to send to the learning scheme</span>\n",
    "\n",
    "This follows the feature and target pairing of the fundamental nature of the supervised learning scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Tuple{Matrix{Int64}, Matrix{Int64}}}:\n",
       " ([0 1 … 4 5], [2 6 … 18 22])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(x_train, y_train)] #array of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[1.5517563;;], Float32[0.0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = Flux.params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Train the model parameters now</span>\n",
    "\n",
    "The training uses the gradient from the optimizer to change the parameters so that the model loss is reduced (descent of the loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss original = 83.42649\n",
      "loss after training = 0.4562064\n"
     ]
    }
   ],
   "source": [
    "println(\"loss original = $(loss(x_train,y_train))\")\n",
    "\n",
    "Flux.train!(loss, parameters, data, opt)\n",
    "\n",
    "println(\"loss after training = $(loss(x_train,y_train))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float32}:\n",
       " 4.29598"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float32}:\n",
       " 0.81206095"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Let us redo the learning scheme but differently this time</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1 => 1)       \u001b[90m# 2 parameters\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dense(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float32}:\n",
       " -1.2775202"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float32}:\n",
       " 0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-1.2775202;;], Float32[0.0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = Flux.params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.0872f0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(1:20) #get a random number from the range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Use the Stochastic approach (faster) as the gradient for each data point is not being calculated</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss original = 312.0872\n",
      "(1, 6)\n",
      "loss after training = 3.031649e-13\n"
     ]
    }
   ],
   "source": [
    "println(\"loss original = $(loss(x_train,y_train))\")\n",
    "\n",
    "(mm,nn) = size(x_train)\n",
    "println(size(x_train))\n",
    "for epoch in 1:1_000\n",
    "    ii = rand(1:nn)\n",
    "    data = [(x_train[:,ii],y_train[:,ii])]\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end\n",
    "\n",
    "println(\"loss after training = $(loss(x_train,y_train))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float32}:\n",
       " 3.9999998"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float32}:\n",
       " 2.000001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip180\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip180)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip181\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip180)\" d=\"\n",
       "M187.084 1486.45 L2352.76 1486.45 L2352.76 47.2441 L187.084 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip182\">\n",
       "    <rect x=\"187\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  248.377,1486.45 248.377,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  759.148,1486.45 759.148,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1269.92,1486.45 1269.92,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1780.69,1486.45 1780.69,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2291.46,1486.45 2291.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  248.377,1486.45 248.377,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  759.148,1486.45 759.148,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1269.92,1486.45 1269.92,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1780.69,1486.45 1780.69,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.46,1486.45 2291.46,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"M248.782 1529.7 Q245.634 1529.7 243.782 1531.86 Q241.953 1534.01 241.953 1537.76 Q241.953 1541.49 243.782 1543.66 Q245.634 1545.82 248.782 1545.82 Q251.93 1545.82 253.759 1543.66 Q255.611 1541.49 255.611 1537.76 Q255.611 1534.01 253.759 1531.86 Q251.93 1529.7 248.782 1529.7 M258.064 1515.05 L258.064 1519.31 Q256.305 1518.48 254.499 1518.04 Q252.717 1517.6 250.958 1517.6 Q246.328 1517.6 243.874 1520.72 Q241.444 1523.85 241.097 1530.17 Q242.462 1528.15 244.523 1527.09 Q246.583 1526 249.06 1526 Q254.268 1526 257.277 1529.17 Q260.31 1532.32 260.31 1537.76 Q260.31 1543.08 257.161 1546.3 Q254.013 1549.52 248.782 1549.52 Q242.787 1549.52 239.615 1544.94 Q236.444 1540.33 236.444 1531.6 Q236.444 1523.41 240.333 1518.55 Q244.222 1513.66 250.773 1513.66 Q252.532 1513.66 254.314 1514.01 Q256.12 1514.36 258.064 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M748.037 1514.29 L770.259 1514.29 L770.259 1516.28 L757.713 1548.85 L752.829 1548.85 L764.634 1518.22 L748.037 1518.22 L748.037 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1269.92 1532.44 Q1266.59 1532.44 1264.67 1534.22 Q1262.77 1536 1262.77 1539.13 Q1262.77 1542.25 1264.67 1544.03 Q1266.59 1545.82 1269.92 1545.82 Q1273.25 1545.82 1275.17 1544.03 Q1277.1 1542.23 1277.1 1539.13 Q1277.1 1536 1275.17 1534.22 Q1273.28 1532.44 1269.92 1532.44 M1265.24 1530.45 Q1262.23 1529.7 1260.55 1527.64 Q1258.88 1525.58 1258.88 1522.62 Q1258.88 1518.48 1261.82 1516.07 Q1264.78 1513.66 1269.92 1513.66 Q1275.08 1513.66 1278.02 1516.07 Q1280.96 1518.48 1280.96 1522.62 Q1280.96 1525.58 1279.27 1527.64 Q1277.61 1529.7 1274.62 1530.45 Q1278 1531.23 1279.87 1533.52 Q1281.77 1535.82 1281.77 1539.13 Q1281.77 1544.15 1278.69 1546.83 Q1275.64 1549.52 1269.92 1549.52 Q1264.2 1549.52 1261.12 1546.83 Q1258.07 1544.15 1258.07 1539.13 Q1258.07 1535.82 1259.97 1533.52 Q1261.86 1531.23 1265.24 1530.45 M1263.53 1523.06 Q1263.53 1525.75 1265.2 1527.25 Q1266.89 1528.76 1269.92 1528.76 Q1272.93 1528.76 1274.62 1527.25 Q1276.33 1525.75 1276.33 1523.06 Q1276.33 1520.38 1274.62 1518.87 Q1272.93 1517.37 1269.92 1517.37 Q1266.89 1517.37 1265.2 1518.87 Q1263.53 1520.38 1263.53 1523.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M1770.99 1548.13 L1770.99 1543.87 Q1772.75 1544.7 1774.56 1545.14 Q1776.36 1545.58 1778.1 1545.58 Q1782.73 1545.58 1785.16 1542.48 Q1787.61 1539.36 1787.96 1533.01 Q1786.62 1535.01 1784.56 1536.07 Q1782.5 1537.13 1780 1537.13 Q1774.81 1537.13 1771.78 1534.01 Q1768.77 1530.86 1768.77 1525.42 Q1768.77 1520.1 1771.92 1516.88 Q1775.07 1513.66 1780.3 1513.66 Q1786.29 1513.66 1789.44 1518.27 Q1792.61 1522.85 1792.61 1531.6 Q1792.61 1539.77 1788.72 1544.66 Q1784.86 1549.52 1778.31 1549.52 Q1776.55 1549.52 1774.74 1549.17 Q1772.94 1548.82 1770.99 1548.13 M1780.3 1533.48 Q1783.45 1533.48 1785.27 1531.32 Q1787.13 1529.17 1787.13 1525.42 Q1787.13 1521.7 1785.27 1519.54 Q1783.45 1517.37 1780.3 1517.37 Q1777.15 1517.37 1775.3 1519.54 Q1773.47 1521.7 1773.47 1525.42 Q1773.47 1529.17 1775.3 1531.32 Q1777.15 1533.48 1780.3 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M2266.15 1544.91 L2273.79 1544.91 L2273.79 1518.55 L2265.48 1520.21 L2265.48 1515.95 L2273.74 1514.29 L2278.42 1514.29 L2278.42 1544.91 L2286.06 1544.91 L2286.06 1548.85 L2266.15 1548.85 L2266.15 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M2305.5 1517.37 Q2301.89 1517.37 2300.06 1520.93 Q2298.26 1524.47 2298.26 1531.6 Q2298.26 1538.71 2300.06 1542.27 Q2301.89 1545.82 2305.5 1545.82 Q2309.14 1545.82 2310.94 1542.27 Q2312.77 1538.71 2312.77 1531.6 Q2312.77 1524.47 2310.94 1520.93 Q2309.14 1517.37 2305.5 1517.37 M2305.5 1513.66 Q2311.31 1513.66 2314.37 1518.27 Q2317.45 1522.85 2317.45 1531.6 Q2317.45 1540.33 2314.37 1544.94 Q2311.31 1549.52 2305.5 1549.52 Q2299.69 1549.52 2296.61 1544.94 Q2293.56 1540.33 2293.56 1531.6 Q2293.56 1522.85 2296.61 1518.27 Q2299.69 1513.66 2305.5 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,1318.43 2352.76,1318.43 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,1106.28 2352.76,1106.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,894.134 2352.76,894.134 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,681.987 2352.76,681.987 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,469.84 2352.76,469.84 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  187.084,257.694 2352.76,257.694 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,1486.45 187.084,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,1318.43 205.982,1318.43 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,1106.28 205.982,1106.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,894.134 205.982,894.134 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,681.987 205.982,681.987 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,469.84 205.982,469.84 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip180)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  187.084,257.694 205.982,257.694 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip180)\" d=\"M58.7699 1331.77 L75.0892 1331.77 L75.0892 1335.71 L53.1449 1335.71 L53.1449 1331.77 Q55.8069 1329.02 60.3902 1324.39 Q64.9967 1319.74 66.1772 1318.39 Q68.4226 1315.87 69.3022 1314.13 Q70.205 1312.37 70.205 1310.68 Q70.205 1307.93 68.2606 1306.19 Q66.3393 1304.46 63.2374 1304.46 Q61.0384 1304.46 58.5847 1305.22 Q56.1541 1305.99 53.3764 1307.54 L53.3764 1302.81 Q56.2004 1301.68 58.6541 1301.1 Q61.1078 1300.52 63.1448 1300.52 Q68.5152 1300.52 71.7096 1303.21 Q74.904 1305.89 74.904 1310.38 Q74.904 1312.51 74.0939 1314.43 Q73.3068 1316.33 71.2004 1318.93 Q70.6217 1319.6 67.5198 1322.81 Q64.418 1326.01 58.7699 1331.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M83.7234 1301.15 L105.946 1301.15 L105.946 1303.14 L93.3993 1335.71 L88.5151 1335.71 L100.321 1305.08 L83.7234 1305.08 L83.7234 1301.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M115.066 1329.83 L119.95 1329.83 L119.95 1335.71 L115.066 1335.71 L115.066 1329.83 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M130.182 1301.15 L148.538 1301.15 L148.538 1305.08 L134.464 1305.08 L134.464 1313.55 Q135.482 1313.21 136.501 1313.05 Q137.519 1312.86 138.538 1312.86 Q144.325 1312.86 147.705 1316.03 Q151.084 1319.2 151.084 1324.62 Q151.084 1330.2 147.612 1333.3 Q144.14 1336.38 137.82 1336.38 Q135.644 1336.38 133.376 1336.01 Q131.131 1335.64 128.723 1334.9 L128.723 1330.2 Q130.807 1331.33 133.029 1331.89 Q135.251 1332.44 137.728 1332.44 Q141.732 1332.44 144.07 1330.34 Q146.408 1328.23 146.408 1324.62 Q146.408 1321.01 144.07 1318.9 Q141.732 1316.8 137.728 1316.8 Q135.853 1316.8 133.978 1317.21 Q132.126 1317.63 130.182 1318.51 L130.182 1301.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M67.9133 1104.93 Q71.2698 1105.64 73.1448 1107.91 Q75.0429 1110.18 75.0429 1113.51 Q75.0429 1118.63 71.5244 1121.43 Q68.0059 1124.23 61.5245 1124.23 Q59.3486 1124.23 57.0338 1123.79 Q54.7421 1123.38 52.2884 1122.52 L52.2884 1118.01 Q54.2328 1119.14 56.5477 1119.72 Q58.8625 1120.3 61.3856 1120.3 Q65.7837 1120.3 68.0754 1118.56 Q70.3902 1116.82 70.3902 1113.51 Q70.3902 1110.46 68.2374 1108.75 Q66.1078 1107.01 62.2884 1107.01 L58.2606 1107.01 L58.2606 1103.17 L62.4735 1103.17 Q65.9226 1103.17 67.7513 1101.8 Q69.58 1100.41 69.58 1097.82 Q69.58 1095.16 67.6819 1093.75 Q65.8069 1092.31 62.2884 1092.31 Q60.3671 1092.31 58.168 1092.73 Q55.969 1093.14 53.3301 1094.02 L53.3301 1089.86 Q55.9921 1089.12 58.3069 1088.75 Q60.6449 1088.38 62.705 1088.38 Q68.0291 1088.38 71.1309 1090.81 Q74.2327 1093.21 74.2327 1097.33 Q74.2327 1100.2 72.5892 1102.2 Q70.9457 1104.16 67.9133 1104.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M93.9086 1092.08 Q90.2975 1092.08 88.4688 1095.64 Q86.6632 1099.19 86.6632 1106.32 Q86.6632 1113.42 88.4688 1116.99 Q90.2975 1120.53 93.9086 1120.53 Q97.5428 1120.53 99.3483 1116.99 Q101.177 1113.42 101.177 1106.32 Q101.177 1099.19 99.3483 1095.64 Q97.5428 1092.08 93.9086 1092.08 M93.9086 1088.38 Q99.7187 1088.38 102.774 1092.98 Q105.853 1097.57 105.853 1106.32 Q105.853 1115.04 102.774 1119.65 Q99.7187 1124.23 93.9086 1124.23 Q88.0984 1124.23 85.0197 1119.65 Q81.9642 1115.04 81.9642 1106.32 Q81.9642 1097.57 85.0197 1092.98 Q88.0984 1088.38 93.9086 1088.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M114.07 1117.68 L118.955 1117.68 L118.955 1123.56 L114.07 1123.56 L114.07 1117.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M139.14 1092.08 Q135.529 1092.08 133.7 1095.64 Q131.894 1099.19 131.894 1106.32 Q131.894 1113.42 133.7 1116.99 Q135.529 1120.53 139.14 1120.53 Q142.774 1120.53 144.58 1116.99 Q146.408 1113.42 146.408 1106.32 Q146.408 1099.19 144.58 1095.64 Q142.774 1092.08 139.14 1092.08 M139.14 1088.38 Q144.95 1088.38 148.005 1092.98 Q151.084 1097.57 151.084 1106.32 Q151.084 1115.04 148.005 1119.65 Q144.95 1124.23 139.14 1124.23 Q133.33 1124.23 130.251 1119.65 Q127.195 1115.04 127.195 1106.32 Q127.195 1097.57 130.251 1092.98 Q133.33 1088.38 139.14 1088.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M68.9087 892.78 Q72.2652 893.497 74.1402 895.766 Q76.0383 898.034 76.0383 901.368 Q76.0383 906.484 72.5198 909.284 Q69.0013 912.085 62.5198 912.085 Q60.3439 912.085 58.0291 911.646 Q55.7375 911.229 53.2838 910.372 L53.2838 905.859 Q55.2282 906.993 57.543 907.571 Q59.8578 908.15 62.381 908.15 Q66.7791 908.15 69.0707 906.414 Q71.3855 904.678 71.3855 901.368 Q71.3855 898.312 69.2328 896.599 Q67.1032 894.863 63.2837 894.863 L59.256 894.863 L59.256 891.021 L63.4689 891.021 Q66.918 891.021 68.7467 889.655 Q70.5754 888.266 70.5754 885.673 Q70.5754 883.011 68.6772 881.599 Q66.8022 880.164 63.2837 880.164 Q61.3624 880.164 59.1634 880.581 Q56.9643 880.998 54.3254 881.877 L54.3254 877.711 Q56.9875 876.97 59.3023 876.599 Q61.6402 876.229 63.7004 876.229 Q69.0244 876.229 72.1263 878.66 Q75.2281 881.067 75.2281 885.187 Q75.2281 888.058 73.5846 890.048 Q71.9411 892.016 68.9087 892.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M88.9317 907.479 L105.251 907.479 L105.251 911.414 L83.3068 911.414 L83.3068 907.479 Q85.9688 904.724 90.5521 900.095 Q95.1586 895.442 96.3391 894.099 Q98.5845 891.576 99.4641 889.84 Q100.367 888.081 100.367 886.391 Q100.367 883.636 98.4224 881.9 Q96.5011 880.164 93.3993 880.164 Q91.2002 880.164 88.7466 880.928 Q86.316 881.692 83.5382 883.243 L83.5382 878.521 Q86.3623 877.386 88.816 876.808 Q91.2697 876.229 93.3067 876.229 Q98.6771 876.229 101.871 878.914 Q105.066 881.599 105.066 886.09 Q105.066 888.22 104.256 890.141 Q103.469 892.039 101.362 894.632 Q100.784 895.303 97.6817 898.521 Q94.5799 901.715 88.9317 907.479 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M115.066 905.534 L119.95 905.534 L119.95 911.414 L115.066 911.414 L115.066 905.534 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M130.182 876.854 L148.538 876.854 L148.538 880.789 L134.464 880.789 L134.464 889.261 Q135.482 888.914 136.501 888.752 Q137.519 888.567 138.538 888.567 Q144.325 888.567 147.705 891.738 Q151.084 894.909 151.084 900.326 Q151.084 905.905 147.612 909.007 Q144.14 912.085 137.82 912.085 Q135.644 912.085 133.376 911.715 Q131.131 911.345 128.723 910.604 L128.723 905.905 Q130.807 907.039 133.029 907.595 Q135.251 908.15 137.728 908.15 Q141.732 908.15 144.07 906.044 Q146.408 903.937 146.408 900.326 Q146.408 896.715 144.07 894.609 Q141.732 892.502 137.728 892.502 Q135.853 892.502 133.978 892.919 Q132.126 893.335 130.182 894.215 L130.182 876.854 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M67.9133 680.633 Q71.2698 681.351 73.1448 683.619 Q75.0429 685.888 75.0429 689.221 Q75.0429 694.337 71.5244 697.138 Q68.0059 699.939 61.5245 699.939 Q59.3486 699.939 57.0338 699.499 Q54.7421 699.082 52.2884 698.226 L52.2884 693.712 Q54.2328 694.846 56.5477 695.425 Q58.8625 696.003 61.3856 696.003 Q65.7837 696.003 68.0754 694.267 Q70.3902 692.531 70.3902 689.221 Q70.3902 686.165 68.2374 684.453 Q66.1078 682.716 62.2884 682.716 L58.2606 682.716 L58.2606 678.874 L62.4735 678.874 Q65.9226 678.874 67.7513 677.508 Q69.58 676.119 69.58 673.527 Q69.58 670.865 67.6819 669.453 Q65.8069 668.017 62.2884 668.017 Q60.3671 668.017 58.168 668.434 Q55.969 668.851 53.3301 669.73 L53.3301 665.564 Q55.9921 664.823 58.3069 664.453 Q60.6449 664.082 62.705 664.082 Q68.0291 664.082 71.1309 666.513 Q74.2327 668.92 74.2327 673.041 Q74.2327 675.911 72.5892 677.902 Q70.9457 679.869 67.9133 680.633 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M83.9549 664.707 L102.311 664.707 L102.311 668.642 L88.2373 668.642 L88.2373 677.115 Q89.2558 676.767 90.2743 676.605 Q91.2928 676.42 92.3113 676.42 Q98.0984 676.42 101.478 679.591 Q104.858 682.763 104.858 688.179 Q104.858 693.758 101.385 696.86 Q97.9132 699.939 91.5938 699.939 Q89.4178 699.939 87.1493 699.568 Q84.904 699.198 82.4966 698.457 L82.4966 693.758 Q84.5799 694.892 86.8021 695.448 Q89.0243 696.003 91.5012 696.003 Q95.5058 696.003 97.8437 693.897 Q100.182 691.79 100.182 688.179 Q100.182 684.568 97.8437 682.462 Q95.5058 680.355 91.5012 680.355 Q89.6262 680.355 87.7512 680.772 Q85.8993 681.189 83.9549 682.068 L83.9549 664.707 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M114.07 693.388 L118.955 693.388 L118.955 699.267 L114.07 699.267 L114.07 693.388 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M139.14 667.786 Q135.529 667.786 133.7 671.351 Q131.894 674.892 131.894 682.022 Q131.894 689.128 133.7 692.693 Q135.529 696.235 139.14 696.235 Q142.774 696.235 144.58 692.693 Q146.408 689.128 146.408 682.022 Q146.408 674.892 144.58 671.351 Q142.774 667.786 139.14 667.786 M139.14 664.082 Q144.95 664.082 148.005 668.689 Q151.084 673.272 151.084 682.022 Q151.084 690.749 148.005 695.355 Q144.95 699.939 139.14 699.939 Q133.33 699.939 130.251 695.355 Q127.195 690.749 127.195 682.022 Q127.195 673.272 130.251 668.689 Q133.33 664.082 139.14 664.082 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M68.9087 468.486 Q72.2652 469.204 74.1402 471.472 Q76.0383 473.741 76.0383 477.074 Q76.0383 482.19 72.5198 484.991 Q69.0013 487.792 62.5198 487.792 Q60.3439 487.792 58.0291 487.352 Q55.7375 486.935 53.2838 486.079 L53.2838 481.565 Q55.2282 482.699 57.543 483.278 Q59.8578 483.857 62.381 483.857 Q66.7791 483.857 69.0707 482.121 Q71.3855 480.384 71.3855 477.074 Q71.3855 474.019 69.2328 472.306 Q67.1032 470.57 63.2837 470.57 L59.256 470.57 L59.256 466.727 L63.4689 466.727 Q66.918 466.727 68.7467 465.361 Q70.5754 463.972 70.5754 461.38 Q70.5754 458.718 68.6772 457.306 Q66.8022 455.871 63.2837 455.871 Q61.3624 455.871 59.1634 456.287 Q56.9643 456.704 54.3254 457.584 L54.3254 453.417 Q56.9875 452.676 59.3023 452.306 Q61.6402 451.935 63.7004 451.935 Q69.0244 451.935 72.1263 454.366 Q75.2281 456.773 75.2281 460.894 Q75.2281 463.764 73.5846 465.755 Q71.9411 467.722 68.9087 468.486 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M83.7234 452.56 L105.946 452.56 L105.946 454.551 L93.3993 487.12 L88.5151 487.12 L100.321 456.496 L83.7234 456.496 L83.7234 452.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M115.066 481.241 L119.95 481.241 L119.95 487.12 L115.066 487.12 L115.066 481.241 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M130.182 452.56 L148.538 452.56 L148.538 456.496 L134.464 456.496 L134.464 464.968 Q135.482 464.621 136.501 464.459 Q137.519 464.273 138.538 464.273 Q144.325 464.273 147.705 467.445 Q151.084 470.616 151.084 476.033 Q151.084 481.611 147.612 484.713 Q144.14 487.792 137.82 487.792 Q135.644 487.792 133.376 487.421 Q131.131 487.051 128.723 486.31 L128.723 481.611 Q130.807 482.745 133.029 483.301 Q135.251 483.857 137.728 483.857 Q141.732 483.857 144.07 481.75 Q146.408 479.644 146.408 476.033 Q146.408 472.421 144.07 470.315 Q141.732 468.209 137.728 468.209 Q135.853 468.209 133.978 468.625 Q132.126 469.042 130.182 469.921 L130.182 452.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M66.5939 244.488 L54.7884 262.937 L66.5939 262.937 L66.5939 244.488 M65.367 240.414 L71.2466 240.414 L71.2466 262.937 L76.1772 262.937 L76.1772 266.826 L71.2466 266.826 L71.2466 274.974 L66.5939 274.974 L66.5939 266.826 L50.9921 266.826 L50.9921 262.312 L65.367 240.414 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M93.9086 243.492 Q90.2975 243.492 88.4688 247.057 Q86.6632 250.599 86.6632 257.728 Q86.6632 264.835 88.4688 268.4 Q90.2975 271.941 93.9086 271.941 Q97.5428 271.941 99.3483 268.4 Q101.177 264.835 101.177 257.728 Q101.177 250.599 99.3483 247.057 Q97.5428 243.492 93.9086 243.492 M93.9086 239.789 Q99.7187 239.789 102.774 244.395 Q105.853 248.978 105.853 257.728 Q105.853 266.455 102.774 271.062 Q99.7187 275.645 93.9086 275.645 Q88.0984 275.645 85.0197 271.062 Q81.9642 266.455 81.9642 257.728 Q81.9642 248.978 85.0197 244.395 Q88.0984 239.789 93.9086 239.789 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M114.07 269.094 L118.955 269.094 L118.955 274.974 L114.07 274.974 L114.07 269.094 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip180)\" d=\"M139.14 243.492 Q135.529 243.492 133.7 247.057 Q131.894 250.599 131.894 257.728 Q131.894 264.835 133.7 268.4 Q135.529 271.941 139.14 271.941 Q142.774 271.941 144.58 268.4 Q146.408 264.835 146.408 257.728 Q146.408 250.599 144.58 247.057 Q142.774 243.492 139.14 243.492 M139.14 239.789 Q144.95 239.789 148.005 244.395 Q151.084 248.978 151.084 257.728 Q151.084 266.455 148.005 271.062 Q144.95 275.645 139.14 275.645 Q133.33 275.645 130.251 271.062 Q127.195 266.455 127.195 257.728 Q127.195 248.978 130.251 244.395 Q133.33 239.789 139.14 239.789 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip182)\" cx=\"248.377\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip182)\" cx=\"759.148\" cy=\"1106.28\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip182)\" cx=\"1269.92\" cy=\"766.846\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip182)\" cx=\"1780.69\" cy=\"427.411\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip182)\" cx=\"2291.46\" cy=\"87.9763\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip182)\" style=\"stroke:#00a9ad; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  248.377,1445.72 269.014,1432 289.651,1418.29 310.288,1404.57 330.926,1390.86 351.563,1377.14 372.2,1363.43 392.837,1349.71 413.475,1336 434.112,1322.28 \n",
       "  454.749,1308.57 475.386,1294.86 496.024,1281.14 516.661,1267.43 537.298,1253.71 557.935,1240 578.573,1226.28 599.21,1212.57 619.847,1198.85 640.484,1185.14 \n",
       "  661.122,1171.42 681.759,1157.71 702.396,1144 723.033,1130.28 743.67,1116.57 764.308,1102.85 784.945,1089.14 805.582,1075.42 826.219,1061.71 846.857,1047.99 \n",
       "  867.494,1034.28 888.131,1020.57 908.768,1006.85 929.406,993.136 950.043,979.421 970.68,965.707 991.317,951.992 1011.95,938.278 1032.59,924.563 1053.23,910.849 \n",
       "  1073.87,897.134 1094.5,883.42 1115.14,869.705 1135.78,855.991 1156.42,842.276 1177.05,828.561 1197.69,814.847 1218.33,801.132 1238.96,787.418 1259.6,773.703 \n",
       "  1280.24,759.989 1300.88,746.274 1321.51,732.56 1342.15,718.845 1362.79,705.131 1383.42,691.416 1404.06,677.702 1424.7,663.987 1445.34,650.272 1465.97,636.558 \n",
       "  1486.61,622.843 1507.25,609.129 1527.89,595.414 1548.52,581.7 1569.16,567.985 1589.8,554.271 1610.43,540.556 1631.07,526.842 1651.71,513.127 1672.35,499.413 \n",
       "  1692.98,485.698 1713.62,471.983 1734.26,458.269 1754.9,444.554 1775.53,430.84 1796.17,417.125 1816.81,403.411 1837.44,389.696 1858.08,375.982 1878.72,362.267 \n",
       "  1899.36,348.553 1919.99,334.838 1940.63,321.124 1961.27,307.409 1981.9,293.694 2002.54,279.98 2023.18,266.265 2043.82,252.551 2064.45,238.836 2085.09,225.122 \n",
       "  2105.73,211.407 2126.37,197.693 2147,183.978 2167.64,170.264 2188.28,156.549 2208.91,142.835 2229.55,129.12 2250.19,115.405 2270.83,101.691 2291.46,87.9764 \n",
       "  \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(x_test, y_test, legend=false, linetype=\"scatter\", color=\"blue\")\n",
    "domain = LinRange(6,10,100)\n",
    "plot!(domain, domain .* model.weight .+ model.bias, legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Let's make a set of **predictions** from the model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 Matrix{Float64}:\n",
       " 30.0  34.0  4.0  402.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([7 8 .5 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Let us look at the same problem in a slightly different approach</span>\n",
    "\n",
    "- Flux assumes that the features span the 'rows' and not the columns, meaning that each column is a data point. \n",
    "- We often use a **DataLoader** object to encapsulate the features and targets and set the batch size for the SGD\n",
    "- The Adam optimizer is very popular and well known as it handles 'momenta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([222 374 … 366 70], [162 146 … 130 74])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hcat makes sure that this x data is a row and not a default column\n",
    "x_train, x_test = hcat(rand(1:100,20)...), hcat(rand(1:100,20)...)\n",
    "y_train, y_test = target_function.(x_train), target_function.(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLUtils.DataLoader{Tuple{Matrix{Int64}, Matrix{Int64}}, Random._GLOBAL_RNG, Val{nothing}}(([55 93 … 91 17], [222 374 … 366 70]), 2, false, true, true, false, Val{nothing}(), Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand()\n",
    "b = rand()\n",
    "model1(x) = W*x .+ b\n",
    "function loss1(x,y)\n",
    "    y_hat = model1.(x)[1]\n",
    "    sum((y .- y_hat).^2)\n",
    "end\n",
    "pars = Flux.params(model1)\n",
    "opt = Flux.Adam(0.01)      # will store optimiser momentum\n",
    "loader = Flux.DataLoader( (x_train, y_train) , batchsize=2, shuffle=true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 93\n",
      "222 374\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in (x_train,y_train)\n",
    "    println(x,\" \",y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching loss1(::Matrix{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  loss1(::Any, \u001b[91m::Any\u001b[39m) at In[33]:4",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching loss1(::Matrix{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  loss1(::Any, \u001b[91m::Any\u001b[39m) at In[33]:4",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/Zygote/dABKa/src/compiler/interface2.jl:0 [inlined]",
      "  [2] _pullback(ctx::Zygote.Context{true}, f::typeof(loss1), args::Matrix{Int64})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface2.jl:9",
      "  [3] _apply(::Function, ::Vararg{Any})",
      "    @ Core ./boot.jl:816",
      "  [4] adjoint",
      "    @ ~/.julia/packages/Zygote/dABKa/src/lib/lib.jl:203 [inlined]",
      "  [5] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/4k0Ls/src/optimise/train.jl:130 [inlined]",
      "  [7] _pullback(::Zygote.Context{true}, ::Flux.Optimise.var\"#37#40\"{typeof(loss1), Matrix{Int64}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface2.jl:0",
      "  [8] pullback(f::Function, ps::Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface.jl:373",
      "  [9] gradient(f::Function, args::Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/dABKa/src/compiler/interface.jl:96",
      " [10] macro expansion",
      "    @ ~/.julia/packages/Flux/4k0Ls/src/optimise/train.jl:129 [inlined]",
      " [11] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      " [12] train!(loss::Function, ps::Params{Zygote.Buffer{Any, Vector{Any}}}, data::Tuple{Matrix{Int64}, Matrix{Int64}}, opt::Adam; cb::Flux.Optimise.var\"#38#41\")",
      "    @ Flux.Optimise ~/.julia/packages/Flux/4k0Ls/src/optimise/train.jl:127",
      " [13] train!(loss::Function, ps::Params{Zygote.Buffer{Any, Vector{Any}}}, data::Tuple{Matrix{Int64}, Matrix{Int64}}, opt::Adam)",
      "    @ Flux.Optimise ~/.julia/packages/Flux/4k0Ls/src/optimise/train.jl:123",
      " [14] top-level scope",
      "    @ ./In[34]:5",
      " [15] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [16] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "for epoch in 1:1_000\n",
    "    for (x, y) in loader\n",
    "        y_hat = model1(x)\n",
    "        loss1(y, y_hat)\n",
    "        Flux.train!(loss1, pars, (x,y), opt)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18349628499663506"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>\n",
    "### <span style=\"color:orange\"></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">produce some ground truth parameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Int64}:\n",
       " 1  2  3  4  5\n",
       " 5  4  3  2  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_truth = [1 2 3 4 5]\n",
    "display( W_truth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " -2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_truth = [ -2.0 ]\n",
    "display( b_truth )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">produce a ground truth model to produce data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ground_truth_model (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_model(x) = (W_truth * x) .+ b_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">produce some *training feature* data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Float64}}:\n",
       " [2.1208584464907614, 4.163429508817119, 1.7837581819243453, 4.191883360153838, 0.9090654523496511]\n",
       " [2.5236466993444058, 0.5522780451803794, 4.308994851030602, 3.5725598676226236, 2.2233108849818866]\n",
       " [1.0168668447179057, 4.720139202172423, 0.0335506960345161, 4.052071949031639, 1.5691063438533743]\n",
       " [1.537624116410331, 1.7997210953088234, 4.538404390194335, 0.5282918858982111, 1.1087434807820133]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN = 10^3\n",
    "x_train = [ 5 .* rand(5) for _ in 1:NN ]\n",
    "println( size( x_train ) )\n",
    "display( x_train[1:4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">produce some *training target* data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Float64}}:\n",
       " [35.982321957464244, 39.91723968690263]\n",
       " [40.89538747080707, 35.14593318607259]\n",
       " [33.78056442140868, 31.656362480792733]\n",
       " [25.634360399374426, 28.4468328996352]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = [ ground_truth_model(x) + 0.2 .* randn(2) for x in x_train ]\n",
    "println( size( y_train ) )\n",
    "display( y_train[1:4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">define the model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_to_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_fit(x) = W1*x .+ b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Initialize the model parameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 10.27977596938496\n",
       " 10.752576902079465"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = rand( 2, 5 ) .+ 10\n",
    "b1 = rand( 2 ) .+ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">define the loss function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss1 (generic function with 1 method)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss1( x, y )\n",
    "    y_hat = model_to_fit( x ) #y_hat is our prediction based upon the model given the current value of the parameters \n",
    "    sum( ( y .- y_hat ).^2 ) #this is the sum of squared errors (SSE) of the prediction for these parameter values\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">set the optimizer for parameter for the gradients</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.01, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Flux.Adam(0.01) # an alternative is >Descent(0.01)< "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">get the parameters of the model which need to be optimized</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([model_to_fit])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = Params( [model_to_fit] ) # Params is part of Zygote.jl, as Zygote allows a dictionary style retrieval of the parameter variables\n",
    "#alternative forms are >Params([W1,b1])< , using flux >Flux.params(W1, b1)< or >Flux.params(model_to_fit)<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">We can calculate the loss for each setting of the parameters which is needed to find the **gradient** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24237.961876376605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = gradient( Params([W1,b1]) ) do #using Zygote.jl\n",
    "    l1 = loss1(x_train[1],y_train[1])\n",
    "    println(l1)\n",
    "    return l1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Float64}:\n",
       " 479.536  941.371  403.316  947.805  205.544\n",
       " 454.025  891.29   381.86   897.381  194.609"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[W1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 226.10475919027664\n",
       " 214.07588695837143"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[b1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24237.961876376605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = gradient(Flux.params(x_train, y_train)) do #using Flux.jl\n",
    "    l1 = loss1(x_train[1],y_train[1])\n",
    "    println(l1)\n",
    "    return l1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = zip( x_train, y_train )\n",
    "\n",
    "ps = Flux.params( model_to_fit )\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for (x,y) in train_data\n",
    "    gs = gradient( ps ) do #using Flux.jl\n",
    "        l1 = loss1(x,y)\n",
    "        Zygote.ignore_derivatives() do # code in this 'block' is not part of the differentiated set (not part of the optimization)\n",
    "            push!(loss_log, l1)\n",
    "        end\n",
    "        return l1\n",
    "    end\n",
    "    Flux.Optimise.update!(opt, ps, gs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Any}:\n",
       " 24237.961876376605\n",
       " 24093.623717882045\n",
       " 18884.228937818887\n",
       " 13464.934682025541\n",
       "  9472.990301449478\n",
       " 31403.13484342039\n",
       " 16700.79033210296\n",
       " 15297.859388950936\n",
       " 13660.081499067375\n",
       " 12317.934664637005\n",
       " 18941.627383771804\n",
       " 16515.51335477688\n",
       " 22488.66343331941\n",
       "     ⋮\n",
       " 22173.70908233695\n",
       "  8887.247844694572\n",
       " 37537.70818517936\n",
       " 31591.92454538282\n",
       " 17988.07626468913\n",
       " 29712.204483713125\n",
       " 37370.469458890584\n",
       " 19132.197662348208\n",
       " 26474.38283523103\n",
       " 15120.480969724633\n",
       " 36310.313945297996\n",
       " 26813.532422541026"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip770\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip770)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip771\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip770)\" d=\"\n",
       "M277.431 1486.45 L2352.76 1486.45 L2352.76 47.2441 L277.431 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip772\">\n",
       "    <rect x=\"277\" y=\"47\" width=\"2076\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  334.207,1486.45 334.207,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  824.16,1486.45 824.16,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1314.11,1486.45 1314.11,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1804.07,1486.45 1804.07,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2294.02,1486.45 2294.02,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  334.207,1486.45 334.207,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  824.16,1486.45 824.16,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1314.11,1486.45 1314.11,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1804.07,1486.45 1804.07,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2294.02,1486.45 2294.02,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip770)\" d=\"M334.207 1517.37 Q330.596 1517.37 328.767 1520.93 Q326.961 1524.47 326.961 1531.6 Q326.961 1538.71 328.767 1542.27 Q330.596 1545.82 334.207 1545.82 Q337.841 1545.82 339.647 1542.27 Q341.475 1538.71 341.475 1531.6 Q341.475 1524.47 339.647 1520.93 Q337.841 1517.37 334.207 1517.37 M334.207 1513.66 Q340.017 1513.66 343.072 1518.27 Q346.151 1522.85 346.151 1531.6 Q346.151 1540.33 343.072 1544.94 Q340.017 1549.52 334.207 1549.52 Q328.397 1549.52 325.318 1544.94 Q322.262 1540.33 322.262 1531.6 Q322.262 1522.85 325.318 1518.27 Q328.397 1513.66 334.207 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M787.852 1544.91 L804.172 1544.91 L804.172 1548.85 L782.227 1548.85 L782.227 1544.91 Q784.889 1542.16 789.473 1537.53 Q794.079 1532.88 795.26 1531.53 Q797.505 1529.01 798.385 1527.27 Q799.288 1525.51 799.288 1523.82 Q799.288 1521.07 797.343 1519.33 Q795.422 1517.6 792.32 1517.6 Q790.121 1517.6 787.667 1518.36 Q785.237 1519.13 782.459 1520.68 L782.459 1515.95 Q785.283 1514.82 787.737 1514.24 Q790.19 1513.66 792.227 1513.66 Q797.598 1513.66 800.792 1516.35 Q803.987 1519.03 803.987 1523.52 Q803.987 1525.65 803.176 1527.57 Q802.389 1529.47 800.283 1532.07 Q799.704 1532.74 796.602 1535.95 Q793.501 1539.15 787.852 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M814.033 1514.29 L832.389 1514.29 L832.389 1518.22 L818.315 1518.22 L818.315 1526.7 Q819.334 1526.35 820.352 1526.19 Q821.371 1526 822.389 1526 Q828.176 1526 831.556 1529.17 Q834.936 1532.34 834.936 1537.76 Q834.936 1543.34 831.463 1546.44 Q827.991 1549.52 821.672 1549.52 Q819.496 1549.52 817.227 1549.15 Q814.982 1548.78 812.575 1548.04 L812.575 1543.34 Q814.658 1544.47 816.88 1545.03 Q819.102 1545.58 821.579 1545.58 Q825.584 1545.58 827.922 1543.48 Q830.26 1541.37 830.26 1537.76 Q830.26 1534.15 827.922 1532.04 Q825.584 1529.94 821.579 1529.94 Q819.704 1529.94 817.829 1530.35 Q815.977 1530.77 814.033 1531.65 L814.033 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M854.148 1517.37 Q850.537 1517.37 848.709 1520.93 Q846.903 1524.47 846.903 1531.6 Q846.903 1538.71 848.709 1542.27 Q850.537 1545.82 854.148 1545.82 Q857.783 1545.82 859.588 1542.27 Q861.417 1538.71 861.417 1531.6 Q861.417 1524.47 859.588 1520.93 Q857.783 1517.37 854.148 1517.37 M854.148 1513.66 Q859.959 1513.66 863.014 1518.27 Q866.093 1522.85 866.093 1531.6 Q866.093 1540.33 863.014 1544.94 Q859.959 1549.52 854.148 1549.52 Q848.338 1549.52 845.26 1544.94 Q842.204 1540.33 842.204 1531.6 Q842.204 1522.85 845.26 1518.27 Q848.338 1513.66 854.148 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1273.73 1514.29 L1292.09 1514.29 L1292.09 1518.22 L1278.01 1518.22 L1278.01 1526.7 Q1279.03 1526.35 1280.05 1526.19 Q1281.07 1526 1282.09 1526 Q1287.88 1526 1291.25 1529.17 Q1294.63 1532.34 1294.63 1537.76 Q1294.63 1543.34 1291.16 1546.44 Q1287.69 1549.52 1281.37 1549.52 Q1279.19 1549.52 1276.93 1549.15 Q1274.68 1548.78 1272.27 1548.04 L1272.27 1543.34 Q1274.36 1544.47 1276.58 1545.03 Q1278.8 1545.58 1281.28 1545.58 Q1285.28 1545.58 1287.62 1543.48 Q1289.96 1541.37 1289.96 1537.76 Q1289.96 1534.15 1287.62 1532.04 Q1285.28 1529.94 1281.28 1529.94 Q1279.4 1529.94 1277.53 1530.35 Q1275.68 1530.77 1273.73 1531.65 L1273.73 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1313.85 1517.37 Q1310.24 1517.37 1308.41 1520.93 Q1306.6 1524.47 1306.6 1531.6 Q1306.6 1538.71 1308.41 1542.27 Q1310.24 1545.82 1313.85 1545.82 Q1317.48 1545.82 1319.29 1542.27 Q1321.12 1538.71 1321.12 1531.6 Q1321.12 1524.47 1319.29 1520.93 Q1317.48 1517.37 1313.85 1517.37 M1313.85 1513.66 Q1319.66 1513.66 1322.71 1518.27 Q1325.79 1522.85 1325.79 1531.6 Q1325.79 1540.33 1322.71 1544.94 Q1319.66 1549.52 1313.85 1549.52 Q1308.04 1549.52 1304.96 1544.94 Q1301.9 1540.33 1301.9 1531.6 Q1301.9 1522.85 1304.96 1518.27 Q1308.04 1513.66 1313.85 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1344.01 1517.37 Q1340.4 1517.37 1338.57 1520.93 Q1336.76 1524.47 1336.76 1531.6 Q1336.76 1538.71 1338.57 1542.27 Q1340.4 1545.82 1344.01 1545.82 Q1347.64 1545.82 1349.45 1542.27 Q1351.28 1538.71 1351.28 1531.6 Q1351.28 1524.47 1349.45 1520.93 Q1347.64 1517.37 1344.01 1517.37 M1344.01 1513.66 Q1349.82 1513.66 1352.87 1518.27 Q1355.95 1522.85 1355.95 1531.6 Q1355.95 1540.33 1352.87 1544.94 Q1349.82 1549.52 1344.01 1549.52 Q1338.2 1549.52 1335.12 1544.94 Q1332.06 1540.33 1332.06 1531.6 Q1332.06 1522.85 1335.12 1518.27 Q1338.2 1513.66 1344.01 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1762.34 1514.29 L1784.56 1514.29 L1784.56 1516.28 L1772.02 1548.85 L1767.13 1548.85 L1778.94 1518.22 L1762.34 1518.22 L1762.34 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1793.73 1514.29 L1812.09 1514.29 L1812.09 1518.22 L1798.01 1518.22 L1798.01 1526.7 Q1799.03 1526.35 1800.05 1526.19 Q1801.07 1526 1802.09 1526 Q1807.87 1526 1811.25 1529.17 Q1814.63 1532.34 1814.63 1537.76 Q1814.63 1543.34 1811.16 1546.44 Q1807.69 1549.52 1801.37 1549.52 Q1799.19 1549.52 1796.93 1549.15 Q1794.68 1548.78 1792.27 1548.04 L1792.27 1543.34 Q1794.36 1544.47 1796.58 1545.03 Q1798.8 1545.58 1801.28 1545.58 Q1805.28 1545.58 1807.62 1543.48 Q1809.96 1541.37 1809.96 1537.76 Q1809.96 1534.15 1807.62 1532.04 Q1805.28 1529.94 1801.28 1529.94 Q1799.4 1529.94 1797.53 1530.35 Q1795.68 1530.77 1793.73 1531.65 L1793.73 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M1833.85 1517.37 Q1830.24 1517.37 1828.41 1520.93 Q1826.6 1524.47 1826.6 1531.6 Q1826.6 1538.71 1828.41 1542.27 Q1830.24 1545.82 1833.85 1545.82 Q1837.48 1545.82 1839.29 1542.27 Q1841.12 1538.71 1841.12 1531.6 Q1841.12 1524.47 1839.29 1520.93 Q1837.48 1517.37 1833.85 1517.37 M1833.85 1513.66 Q1839.66 1513.66 1842.71 1518.27 Q1845.79 1522.85 1845.79 1531.6 Q1845.79 1540.33 1842.71 1544.94 Q1839.66 1549.52 1833.85 1549.52 Q1828.04 1549.52 1824.96 1544.94 Q1821.9 1540.33 1821.9 1531.6 Q1821.9 1522.85 1824.96 1518.27 Q1828.04 1513.66 1833.85 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2238.55 1544.91 L2246.18 1544.91 L2246.18 1518.55 L2237.87 1520.21 L2237.87 1515.95 L2246.14 1514.29 L2250.81 1514.29 L2250.81 1544.91 L2258.45 1544.91 L2258.45 1548.85 L2238.55 1548.85 L2238.55 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2277.9 1517.37 Q2274.29 1517.37 2272.46 1520.93 Q2270.65 1524.47 2270.65 1531.6 Q2270.65 1538.71 2272.46 1542.27 Q2274.29 1545.82 2277.9 1545.82 Q2281.53 1545.82 2283.34 1542.27 Q2285.17 1538.71 2285.17 1531.6 Q2285.17 1524.47 2283.34 1520.93 Q2281.53 1517.37 2277.9 1517.37 M2277.9 1513.66 Q2283.71 1513.66 2286.76 1518.27 Q2289.84 1522.85 2289.84 1531.6 Q2289.84 1540.33 2286.76 1544.94 Q2283.71 1549.52 2277.9 1549.52 Q2272.09 1549.52 2269.01 1544.94 Q2265.95 1540.33 2265.95 1531.6 Q2265.95 1522.85 2269.01 1518.27 Q2272.09 1513.66 2277.9 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2308.06 1517.37 Q2304.45 1517.37 2302.62 1520.93 Q2300.81 1524.47 2300.81 1531.6 Q2300.81 1538.71 2302.62 1542.27 Q2304.45 1545.82 2308.06 1545.82 Q2311.69 1545.82 2313.5 1542.27 Q2315.33 1538.71 2315.33 1531.6 Q2315.33 1524.47 2313.5 1520.93 Q2311.69 1517.37 2308.06 1517.37 M2308.06 1513.66 Q2313.87 1513.66 2316.93 1518.27 Q2320 1522.85 2320 1531.6 Q2320 1540.33 2316.93 1544.94 Q2313.87 1549.52 2308.06 1549.52 Q2302.25 1549.52 2299.17 1544.94 Q2296.12 1540.33 2296.12 1531.6 Q2296.12 1522.85 2299.17 1518.27 Q2302.25 1513.66 2308.06 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2338.22 1517.37 Q2334.61 1517.37 2332.78 1520.93 Q2330.98 1524.47 2330.98 1531.6 Q2330.98 1538.71 2332.78 1542.27 Q2334.61 1545.82 2338.22 1545.82 Q2341.86 1545.82 2343.66 1542.27 Q2345.49 1538.71 2345.49 1531.6 Q2345.49 1524.47 2343.66 1520.93 Q2341.86 1517.37 2338.22 1517.37 M2338.22 1513.66 Q2344.03 1513.66 2347.09 1518.27 Q2350.17 1522.85 2350.17 1531.6 Q2350.17 1540.33 2347.09 1544.94 Q2344.03 1549.52 2338.22 1549.52 Q2332.41 1549.52 2329.33 1544.94 Q2326.28 1540.33 2326.28 1531.6 Q2326.28 1522.85 2329.33 1518.27 Q2332.41 1513.66 2338.22 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,1294.77 2352.76,1294.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,1084.02 2352.76,1084.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,873.275 2352.76,873.275 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,662.525 2352.76,662.525 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,451.776 2352.76,451.776 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip772)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  277.431,241.026 2352.76,241.026 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,1486.45 277.431,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,1294.77 296.329,1294.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,1084.02 296.329,1084.02 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,873.275 296.329,873.275 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,662.525 296.329,662.525 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,451.776 296.329,451.776 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  277.431,241.026 296.329,241.026 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip770)\" d=\"M54.5569 1314.57 L62.1958 1314.57 L62.1958 1288.2 L53.8856 1289.87 L53.8856 1285.61 L62.1495 1283.94 L66.8254 1283.94 L66.8254 1314.57 L74.4642 1314.57 L74.4642 1318.5 L54.5569 1318.5 L54.5569 1314.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 1312.62 L88.7928 1312.62 L88.7928 1318.5 L83.9086 1318.5 L83.9086 1312.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 1287.02 Q105.367 1287.02 103.538 1290.59 Q101.733 1294.13 101.733 1301.26 Q101.733 1308.36 103.538 1311.93 Q105.367 1315.47 108.978 1315.47 Q112.612 1315.47 114.418 1311.93 Q116.246 1308.36 116.246 1301.26 Q116.246 1294.13 114.418 1290.59 Q112.612 1287.02 108.978 1287.02 M108.978 1283.32 Q114.788 1283.32 117.844 1287.92 Q120.922 1292.51 120.922 1301.26 Q120.922 1309.98 117.844 1314.59 Q114.788 1319.17 108.978 1319.17 Q103.168 1319.17 100.089 1314.59 Q97.0335 1309.98 97.0335 1301.26 Q97.0335 1292.51 100.089 1287.92 Q103.168 1283.32 108.978 1283.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 1293.04 L146.732 1303.66 L157.311 1314.24 L154.556 1317.04 L143.931 1306.42 L133.306 1317.04 L130.575 1314.24 L141.131 1303.66 L130.575 1293.04 L133.306 1290.24 L143.931 1300.86 L154.556 1290.24 L157.311 1293.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 1314.57 L177.311 1314.57 L177.311 1288.2 L169.001 1289.87 L169.001 1285.61 L177.265 1283.94 L181.94 1283.94 L181.94 1314.57 L189.579 1314.57 L189.579 1318.5 L169.672 1318.5 L169.672 1314.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 1287.02 Q205.413 1287.02 203.584 1290.59 Q201.778 1294.13 201.778 1301.26 Q201.778 1308.36 203.584 1311.93 Q205.413 1315.47 209.024 1315.47 Q212.658 1315.47 214.463 1311.93 Q216.292 1308.36 216.292 1301.26 Q216.292 1294.13 214.463 1290.59 Q212.658 1287.02 209.024 1287.02 M209.024 1283.32 Q214.834 1283.32 217.889 1287.92 Q220.968 1292.51 220.968 1301.26 Q220.968 1309.98 217.889 1314.59 Q214.834 1319.17 209.024 1319.17 Q203.214 1319.17 200.135 1314.59 Q197.079 1309.98 197.079 1301.26 Q197.079 1292.51 200.135 1287.92 Q203.214 1283.32 209.024 1283.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 1266.32 L224.053 1281.31 L233.645 1281.31 L233.645 1266.32 M232.648 1263.01 L237.425 1263.01 L237.425 1281.31 L241.431 1281.31 L241.431 1284.47 L237.425 1284.47 L237.425 1291.09 L233.645 1291.09 L233.645 1284.47 L220.968 1284.47 L220.968 1280.8 L232.648 1263.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M57.7745 1103.82 L74.0939 1103.82 L74.0939 1107.75 L52.1495 1107.75 L52.1495 1103.82 Q54.8115 1101.06 59.3949 1096.43 Q64.0013 1091.78 65.1819 1090.44 Q67.4272 1087.91 68.3068 1086.18 Q69.2096 1084.42 69.2096 1082.73 Q69.2096 1079.97 67.2652 1078.24 Q65.3439 1076.5 62.2421 1076.5 Q60.043 1076.5 57.5893 1077.27 Q55.1588 1078.03 52.381 1079.58 L52.381 1074.86 Q55.2051 1073.72 57.6588 1073.15 Q60.1124 1072.57 62.1495 1072.57 Q67.5198 1072.57 70.7142 1075.25 Q73.9087 1077.94 73.9087 1082.43 Q73.9087 1084.56 73.0985 1086.48 Q72.3115 1088.38 70.205 1090.97 Q69.6263 1091.64 66.5245 1094.86 Q63.4226 1098.05 57.7745 1103.82 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 1101.87 L88.7928 1101.87 L88.7928 1107.75 L83.9086 1107.75 L83.9086 1101.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 1076.27 Q105.367 1076.27 103.538 1079.84 Q101.733 1083.38 101.733 1090.51 Q101.733 1097.61 103.538 1101.18 Q105.367 1104.72 108.978 1104.72 Q112.612 1104.72 114.418 1101.18 Q116.246 1097.61 116.246 1090.51 Q116.246 1083.38 114.418 1079.84 Q112.612 1076.27 108.978 1076.27 M108.978 1072.57 Q114.788 1072.57 117.844 1077.17 Q120.922 1081.76 120.922 1090.51 Q120.922 1099.23 117.844 1103.84 Q114.788 1108.42 108.978 1108.42 Q103.168 1108.42 100.089 1103.84 Q97.0335 1099.23 97.0335 1090.51 Q97.0335 1081.76 100.089 1077.17 Q103.168 1072.57 108.978 1072.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 1082.29 L146.732 1092.91 L157.311 1103.49 L154.556 1106.29 L143.931 1095.67 L133.306 1106.29 L130.575 1103.49 L141.131 1092.91 L130.575 1082.29 L133.306 1079.49 L143.931 1090.11 L154.556 1079.49 L157.311 1082.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 1103.82 L177.311 1103.82 L177.311 1077.45 L169.001 1079.12 L169.001 1074.86 L177.265 1073.19 L181.94 1073.19 L181.94 1103.82 L189.579 1103.82 L189.579 1107.75 L169.672 1107.75 L169.672 1103.82 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 1076.27 Q205.413 1076.27 203.584 1079.84 Q201.778 1083.38 201.778 1090.51 Q201.778 1097.61 203.584 1101.18 Q205.413 1104.72 209.024 1104.72 Q212.658 1104.72 214.463 1101.18 Q216.292 1097.61 216.292 1090.51 Q216.292 1083.38 214.463 1079.84 Q212.658 1076.27 209.024 1076.27 M209.024 1072.57 Q214.834 1072.57 217.889 1077.17 Q220.968 1081.76 220.968 1090.51 Q220.968 1099.23 217.889 1103.84 Q214.834 1108.42 209.024 1108.42 Q203.214 1108.42 200.135 1103.84 Q197.079 1099.23 197.079 1090.51 Q197.079 1081.76 200.135 1077.17 Q203.214 1072.57 209.024 1072.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 1055.57 L224.053 1070.56 L233.645 1070.56 L233.645 1055.57 M232.648 1052.26 L237.425 1052.26 L237.425 1070.56 L241.431 1070.56 L241.431 1073.72 L237.425 1073.72 L237.425 1080.34 L233.645 1080.34 L233.645 1073.72 L220.968 1073.72 L220.968 1070.05 L232.648 1052.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M67.9133 878.369 Q71.2698 879.086 73.1448 881.355 Q75.0429 883.623 75.0429 886.956 Q75.0429 892.072 71.5244 894.873 Q68.0059 897.674 61.5245 897.674 Q59.3486 897.674 57.0338 897.234 Q54.7421 896.818 52.2884 895.961 L52.2884 891.447 Q54.2328 892.581 56.5477 893.16 Q58.8625 893.739 61.3856 893.739 Q65.7837 893.739 68.0754 892.003 Q70.3902 890.267 70.3902 886.956 Q70.3902 883.901 68.2374 882.188 Q66.1078 880.452 62.2884 880.452 L58.2606 880.452 L58.2606 876.609 L62.4735 876.609 Q65.9226 876.609 67.7513 875.244 Q69.58 873.855 69.58 871.262 Q69.58 868.6 67.6819 867.188 Q65.8069 865.753 62.2884 865.753 Q60.3671 865.753 58.168 866.17 Q55.969 866.586 53.3301 867.466 L53.3301 863.299 Q55.9921 862.558 58.3069 862.188 Q60.6449 861.818 62.705 861.818 Q68.0291 861.818 71.1309 864.248 Q74.2327 866.656 74.2327 870.776 Q74.2327 873.646 72.5892 875.637 Q70.9457 877.605 67.9133 878.369 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 891.123 L88.7928 891.123 L88.7928 897.003 L83.9086 897.003 L83.9086 891.123 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 865.521 Q105.367 865.521 103.538 869.086 Q101.733 872.628 101.733 879.757 Q101.733 886.864 103.538 890.429 Q105.367 893.97 108.978 893.97 Q112.612 893.97 114.418 890.429 Q116.246 886.864 116.246 879.757 Q116.246 872.628 114.418 869.086 Q112.612 865.521 108.978 865.521 M108.978 861.818 Q114.788 861.818 117.844 866.424 Q120.922 871.008 120.922 879.757 Q120.922 888.484 117.844 893.091 Q114.788 897.674 108.978 897.674 Q103.168 897.674 100.089 893.091 Q97.0335 888.484 97.0335 879.757 Q97.0335 871.008 100.089 866.424 Q103.168 861.818 108.978 861.818 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 871.54 L146.732 882.165 L157.311 892.744 L154.556 895.544 L143.931 884.919 L133.306 895.544 L130.575 892.744 L141.131 882.165 L130.575 871.54 L133.306 868.739 L143.931 879.364 L154.556 868.739 L157.311 871.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 893.068 L177.311 893.068 L177.311 866.702 L169.001 868.369 L169.001 864.109 L177.265 862.443 L181.94 862.443 L181.94 893.068 L189.579 893.068 L189.579 897.003 L169.672 897.003 L169.672 893.068 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 865.521 Q205.413 865.521 203.584 869.086 Q201.778 872.628 201.778 879.757 Q201.778 886.864 203.584 890.429 Q205.413 893.97 209.024 893.97 Q212.658 893.97 214.463 890.429 Q216.292 886.864 216.292 879.757 Q216.292 872.628 214.463 869.086 Q212.658 865.521 209.024 865.521 M209.024 861.818 Q214.834 861.818 217.889 866.424 Q220.968 871.008 220.968 879.757 Q220.968 888.484 217.889 893.091 Q214.834 897.674 209.024 897.674 Q203.214 897.674 200.135 893.091 Q197.079 888.484 197.079 879.757 Q197.079 871.008 200.135 866.424 Q203.214 861.818 209.024 861.818 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 844.823 L224.053 859.812 L233.645 859.812 L233.645 844.823 M232.648 841.512 L237.425 841.512 L237.425 859.812 L241.431 859.812 L241.431 862.972 L237.425 862.972 L237.425 869.592 L233.645 869.592 L233.645 862.972 L220.968 862.972 L220.968 859.304 L232.648 841.512 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M66.5939 655.767 L54.7884 674.216 L66.5939 674.216 L66.5939 655.767 M65.367 651.693 L71.2466 651.693 L71.2466 674.216 L76.1772 674.216 L76.1772 678.105 L71.2466 678.105 L71.2466 686.253 L66.5939 686.253 L66.5939 678.105 L50.9921 678.105 L50.9921 673.591 L65.367 651.693 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 680.373 L88.7928 680.373 L88.7928 686.253 L83.9086 686.253 L83.9086 680.373 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 654.772 Q105.367 654.772 103.538 658.337 Q101.733 661.878 101.733 669.008 Q101.733 676.114 103.538 679.679 Q105.367 683.221 108.978 683.221 Q112.612 683.221 114.418 679.679 Q116.246 676.114 116.246 669.008 Q116.246 661.878 114.418 658.337 Q112.612 654.772 108.978 654.772 M108.978 651.068 Q114.788 651.068 117.844 655.675 Q120.922 660.258 120.922 669.008 Q120.922 677.735 117.844 682.341 Q114.788 686.924 108.978 686.924 Q103.168 686.924 100.089 682.341 Q97.0335 677.735 97.0335 669.008 Q97.0335 660.258 100.089 655.675 Q103.168 651.068 108.978 651.068 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 660.79 L146.732 671.415 L157.311 681.994 L154.556 684.795 L143.931 674.17 L133.306 684.795 L130.575 681.994 L141.131 671.415 L130.575 660.79 L133.306 657.989 L143.931 668.614 L154.556 657.989 L157.311 660.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 682.318 L177.311 682.318 L177.311 655.952 L169.001 657.619 L169.001 653.36 L177.265 651.693 L181.94 651.693 L181.94 682.318 L189.579 682.318 L189.579 686.253 L169.672 686.253 L169.672 682.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 654.772 Q205.413 654.772 203.584 658.337 Q201.778 661.878 201.778 669.008 Q201.778 676.114 203.584 679.679 Q205.413 683.221 209.024 683.221 Q212.658 683.221 214.463 679.679 Q216.292 676.114 216.292 669.008 Q216.292 661.878 214.463 658.337 Q212.658 654.772 209.024 654.772 M209.024 651.068 Q214.834 651.068 217.889 655.675 Q220.968 660.258 220.968 669.008 Q220.968 677.735 217.889 682.341 Q214.834 686.924 209.024 686.924 Q203.214 686.924 200.135 682.341 Q197.079 677.735 197.079 669.008 Q197.079 660.258 200.135 655.675 Q203.214 651.068 209.024 651.068 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 634.073 L224.053 649.063 L233.645 649.063 L233.645 634.073 M232.648 630.763 L237.425 630.763 L237.425 649.063 L241.431 649.063 L241.431 652.222 L237.425 652.222 L237.425 658.843 L233.645 658.843 L233.645 652.222 L220.968 652.222 L220.968 648.555 L232.648 630.763 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M53.793 440.943 L72.1494 440.943 L72.1494 444.879 L58.0754 444.879 L58.0754 453.351 Q59.0939 453.003 60.1124 452.841 Q61.131 452.656 62.1495 452.656 Q67.9365 452.656 71.3161 455.828 Q74.6957 458.999 74.6957 464.415 Q74.6957 469.994 71.2235 473.096 Q67.7513 476.175 61.4319 476.175 Q59.256 476.175 56.9875 475.804 Q54.7421 475.434 52.3347 474.693 L52.3347 469.994 Q54.418 471.128 56.6402 471.684 Q58.8625 472.24 61.3393 472.24 Q65.3439 472.24 67.6819 470.133 Q70.0198 468.027 70.0198 464.415 Q70.0198 460.804 67.6819 458.698 Q65.3439 456.591 61.3393 456.591 Q59.4643 456.591 57.5893 457.008 Q55.7375 457.425 53.793 458.304 L53.793 440.943 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 469.624 L88.7928 469.624 L88.7928 475.503 L83.9086 475.503 L83.9086 469.624 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 444.022 Q105.367 444.022 103.538 447.587 Q101.733 451.129 101.733 458.258 Q101.733 465.365 103.538 468.929 Q105.367 472.471 108.978 472.471 Q112.612 472.471 114.418 468.929 Q116.246 465.365 116.246 458.258 Q116.246 451.129 114.418 447.587 Q112.612 444.022 108.978 444.022 M108.978 440.318 Q114.788 440.318 117.844 444.925 Q120.922 449.508 120.922 458.258 Q120.922 466.985 117.844 471.591 Q114.788 476.175 108.978 476.175 Q103.168 476.175 100.089 471.591 Q97.0335 466.985 97.0335 458.258 Q97.0335 449.508 100.089 444.925 Q103.168 440.318 108.978 440.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 450.041 L146.732 460.665 L157.311 471.244 L154.556 474.045 L143.931 463.42 L133.306 474.045 L130.575 471.244 L141.131 460.665 L130.575 450.041 L133.306 447.24 L143.931 457.865 L154.556 447.24 L157.311 450.041 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 471.568 L177.311 471.568 L177.311 445.203 L169.001 446.869 L169.001 442.61 L177.265 440.943 L181.94 440.943 L181.94 471.568 L189.579 471.568 L189.579 475.503 L169.672 475.503 L169.672 471.568 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 444.022 Q205.413 444.022 203.584 447.587 Q201.778 451.129 201.778 458.258 Q201.778 465.365 203.584 468.929 Q205.413 472.471 209.024 472.471 Q212.658 472.471 214.463 468.929 Q216.292 465.365 216.292 458.258 Q216.292 451.129 214.463 447.587 Q212.658 444.022 209.024 444.022 M209.024 440.318 Q214.834 440.318 217.889 444.925 Q220.968 449.508 220.968 458.258 Q220.968 466.985 217.889 471.591 Q214.834 476.175 209.024 476.175 Q203.214 476.175 200.135 471.591 Q197.079 466.985 197.079 458.258 Q197.079 449.508 200.135 444.925 Q203.214 440.318 209.024 440.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 423.323 L224.053 438.313 L233.645 438.313 L233.645 423.323 M232.648 420.013 L237.425 420.013 L237.425 438.313 L241.431 438.313 L241.431 441.473 L237.425 441.473 L237.425 448.093 L233.645 448.093 L233.645 441.473 L220.968 441.473 L220.968 437.805 L232.648 420.013 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M64.3254 245.61 Q61.1773 245.61 59.3254 247.763 Q57.4967 249.916 57.4967 253.666 Q57.4967 257.393 59.3254 259.569 Q61.1773 261.721 64.3254 261.721 Q67.4735 261.721 69.3022 259.569 Q71.1541 257.393 71.1541 253.666 Q71.1541 249.916 69.3022 247.763 Q67.4735 245.61 64.3254 245.61 M73.6077 230.958 L73.6077 235.217 Q71.8485 234.383 70.0429 233.944 Q68.2606 233.504 66.5013 233.504 Q61.8717 233.504 59.418 236.629 Q56.9875 239.754 56.6402 246.073 Q58.006 244.059 60.0662 242.995 Q62.1263 241.907 64.6032 241.907 Q69.8115 241.907 72.8207 245.078 Q75.8531 248.226 75.8531 253.666 Q75.8531 258.99 72.705 262.207 Q69.5568 265.425 64.3254 265.425 Q58.33 265.425 55.1588 260.842 Q51.9875 256.235 51.9875 247.508 Q51.9875 239.314 55.8764 234.453 Q59.7652 229.569 66.3161 229.569 Q68.0754 229.569 69.8578 229.916 Q71.6633 230.263 73.6077 230.958 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M83.9086 258.874 L88.7928 258.874 L88.7928 264.754 L83.9086 264.754 L83.9086 258.874 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M108.978 233.272 Q105.367 233.272 103.538 236.837 Q101.733 240.379 101.733 247.508 Q101.733 254.615 103.538 258.18 Q105.367 261.721 108.978 261.721 Q112.612 261.721 114.418 258.18 Q116.246 254.615 116.246 247.508 Q116.246 240.379 114.418 236.837 Q112.612 233.272 108.978 233.272 M108.978 229.569 Q114.788 229.569 117.844 234.175 Q120.922 238.758 120.922 247.508 Q120.922 256.235 117.844 260.842 Q114.788 265.425 108.978 265.425 Q103.168 265.425 100.089 260.842 Q97.0335 256.235 97.0335 247.508 Q97.0335 238.758 100.089 234.175 Q103.168 229.569 108.978 229.569 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M157.311 239.291 L146.732 249.916 L157.311 260.494 L154.556 263.295 L143.931 252.67 L133.306 263.295 L130.575 260.494 L141.131 249.916 L130.575 239.291 L133.306 236.49 L143.931 247.115 L154.556 236.49 L157.311 239.291 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M169.672 260.819 L177.311 260.819 L177.311 234.453 L169.001 236.12 L169.001 231.86 L177.265 230.194 L181.94 230.194 L181.94 260.819 L189.579 260.819 L189.579 264.754 L169.672 264.754 L169.672 260.819 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M209.024 233.272 Q205.413 233.272 203.584 236.837 Q201.778 240.379 201.778 247.508 Q201.778 254.615 203.584 258.18 Q205.413 261.721 209.024 261.721 Q212.658 261.721 214.463 258.18 Q216.292 254.615 216.292 247.508 Q216.292 240.379 214.463 236.837 Q212.658 233.272 209.024 233.272 M209.024 229.569 Q214.834 229.569 217.889 234.175 Q220.968 238.758 220.968 247.508 Q220.968 256.235 217.889 260.842 Q214.834 265.425 209.024 265.425 Q203.214 265.425 200.135 260.842 Q197.079 256.235 197.079 247.508 Q197.079 238.758 200.135 234.175 Q203.214 229.569 209.024 229.569 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M233.645 212.573 L224.053 227.563 L233.645 227.563 L233.645 212.573 M232.648 209.263 L237.425 209.263 L237.425 227.563 L241.431 227.563 L241.431 230.723 L237.425 230.723 L237.425 237.343 L233.645 237.343 L233.645 230.723 L220.968 230.723 L220.968 227.055 L232.648 209.263 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip772)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  336.167,994.71 338.126,997.752 340.086,1107.54 342.046,1221.75 344.006,1305.88 345.966,843.704 347.925,1153.56 349.885,1183.12 351.845,1217.64 353.805,1245.92 \n",
       "  355.765,1106.33 357.724,1157.46 359.684,1031.58 361.644,483.219 363.604,1030.69 365.564,1288.01 367.524,621.351 369.483,830.678 371.443,665.232 373.403,1069.23 \n",
       "  375.363,1151.65 377.323,1097.14 379.282,725.589 381.242,1023.7 383.202,1016.91 385.162,1152.38 387.122,1305.87 389.081,883.41 391.041,1239.67 393.001,1135.99 \n",
       "  394.961,1011.21 396.921,1003.85 398.881,1168.65 400.84,834.066 402.8,1036.07 404.76,703.321 406.72,988.877 408.68,1228.27 410.639,1038.02 412.599,986.386 \n",
       "  414.559,1335.61 416.519,1152.03 418.479,1293.45 420.439,1249.86 422.398,1181.68 424.358,1001.61 426.318,1131.2 428.278,1071.36 430.238,882.657 432.197,1024.12 \n",
       "  434.157,646.092 436.117,1175.89 438.077,1180.62 440.037,1091.7 441.996,1433.84 443.956,1178.75 445.916,813.629 447.876,1278.85 449.836,698.461 451.796,769.481 \n",
       "  453.755,1104.22 455.715,1135.39 457.675,1224.32 459.635,1060.86 461.595,878.282 463.554,1186.95 465.514,987.242 467.474,1248.83 469.434,1245.52 471.394,1029 \n",
       "  473.353,475.772 475.313,1276.77 477.273,871.178 479.233,1341.89 481.193,962.568 483.153,1040.17 485.112,959.825 487.072,845.388 489.032,1232.75 490.992,838.137 \n",
       "  492.952,1061.22 494.911,927.378 496.871,917.716 498.831,1374.58 500.791,1038.38 502.751,888.187 504.711,881.131 506.67,1076.52 508.63,1068.52 510.59,1248.02 \n",
       "  512.55,1229.96 514.51,989.022 516.469,1219.16 518.429,1239.8 520.389,1104.97 522.349,1217.53 524.309,1071.5 526.268,623.386 528.228,1167.35 530.188,986.991 \n",
       "  532.148,997.857 534.108,963.961 536.068,1104.45 538.027,1232.55 539.987,1331.73 541.947,792.32 543.907,1037.68 545.867,796.441 547.826,1008.7 549.786,709.836 \n",
       "  551.746,777.615 553.706,697.473 555.666,1287.26 557.625,1344.53 559.585,1044.87 561.545,1085.09 563.505,1095.12 565.465,1172.04 567.425,889.917 569.384,1123.18 \n",
       "  571.344,1241.03 573.304,914.644 575.264,748.838 577.224,733.722 579.183,915.189 581.143,987.791 583.103,638.113 585.063,1200.6 587.023,1359.05 588.982,1055.94 \n",
       "  590.942,1015.94 592.902,945.506 594.862,1368.05 596.822,1013.41 598.782,1325.93 600.741,1315.78 602.701,940.809 604.661,1069.52 606.621,1146.52 608.581,1269.32 \n",
       "  610.54,1175.52 612.5,744.453 614.46,640.119 616.42,966.545 618.38,876.488 620.34,1302.31 622.299,1045.1 624.259,638.561 626.219,966.292 628.179,1019.69 \n",
       "  630.139,1122.27 632.098,1017.78 634.058,1024.02 636.018,1135.08 637.978,1232.77 639.938,1055.26 641.897,1326.56 643.857,905.781 645.817,843.093 647.777,1205.41 \n",
       "  649.737,1331.74 651.697,1178.65 653.656,799.951 655.616,765.361 657.576,1028.26 659.536,1321.5 661.496,1128.18 663.455,1070.77 665.415,1312.43 667.375,921.261 \n",
       "  669.335,919.247 671.295,1281.74 673.254,1164.51 675.214,1281.53 677.174,1086.89 679.134,1179.05 681.094,1098.28 683.054,875.474 685.013,953.804 686.973,518.563 \n",
       "  688.933,314.654 690.893,838.232 692.853,1367.64 694.812,1164.63 696.772,1314.31 698.732,1017.49 700.692,1262.33 702.652,1174.44 704.611,1289.78 706.571,1040.91 \n",
       "  708.531,750.698 710.491,1217.07 712.451,1014.34 714.411,477.7 716.37,796.489 718.33,1036.48 720.29,1118.66 722.25,605.738 724.21,907.659 726.169,860.88 \n",
       "  728.129,1188.65 730.089,1045.45 732.049,941.953 734.009,1280.09 735.969,926.418 737.928,1031.83 739.888,1320.2 741.848,1101.9 743.808,836.548 745.768,1050.19 \n",
       "  747.727,998.243 749.687,1084.55 751.647,1165.39 753.607,1068.14 755.567,1164.31 757.526,1250.25 759.486,1293.4 761.446,1286.07 763.406,1267.2 765.366,981.636 \n",
       "  767.326,1250.12 769.285,1037.62 771.245,1308.91 773.205,1235.12 775.165,1220.51 777.125,1129.71 779.084,1256.13 781.044,928.108 783.004,840.517 784.964,1213.4 \n",
       "  786.924,1222.05 788.883,823.124 790.843,1392.72 792.803,1088.21 794.763,1195.92 796.723,1128.23 798.683,1185.19 800.642,956.814 802.602,784.645 804.562,586.277 \n",
       "  806.522,990.022 808.482,1302.98 810.441,879.535 812.401,1051.97 814.361,1274.71 816.321,1330.99 818.281,845.628 820.24,1133.06 822.2,1197.13 824.16,940.331 \n",
       "  826.12,1005.24 828.08,1246.47 830.04,1386.19 831.999,1213.71 833.959,974.432 835.919,1092.1 837.879,1142.33 839.839,1019.06 841.798,1170.08 843.758,857.13 \n",
       "  845.718,1025.84 847.678,1002.64 849.638,860.032 851.598,1207.08 853.557,1151.14 855.517,1054.07 857.477,786.551 859.437,1267.23 861.397,883.775 863.356,1244.44 \n",
       "  865.316,906.072 867.276,1221.62 869.236,996.101 871.196,1213.9 873.155,818.252 875.115,972.16 877.075,1097.93 879.035,1063.4 880.995,704.9 882.955,810.177 \n",
       "  884.914,989.913 886.874,1064.9 888.834,616.562 890.794,1321.7 892.754,1004.35 894.713,1267.39 896.673,437.204 898.633,1222.79 900.593,1233.1 902.553,1210.18 \n",
       "  904.512,1331.79 906.472,789.147 908.432,1173.03 910.392,965.224 912.352,938.346 914.312,1244.07 916.271,1156.02 918.231,1223.04 920.191,613.265 922.151,1047.62 \n",
       "  924.111,926.207 926.07,987.096 928.03,1390.07 929.99,1208.54 931.95,961.226 933.91,1042.72 935.869,950.489 937.829,1021.39 939.789,951.824 941.749,1103.68 \n",
       "  943.709,1368.64 945.669,944.692 947.628,973.378 949.588,1019.44 951.548,1241.88 953.508,1309.56 955.468,1276 957.427,1166.94 959.387,1357.85 961.347,456.04 \n",
       "  963.307,609.026 965.267,1088.05 967.227,1119.8 969.186,796.659 971.146,878.78 973.106,905.067 975.066,694.669 977.026,1246.17 978.985,964.731 980.945,1289.67 \n",
       "  982.905,1131.2 984.865,1139.47 986.825,978.361 988.784,789.826 990.744,845.9 992.704,1050.22 994.664,811.328 996.624,1268.87 998.584,1102.98 1000.54,1016.02 \n",
       "  1002.5,971.713 1004.46,830.415 1006.42,1255.02 1008.38,900.441 1010.34,648.985 1012.3,1149.58 1014.26,871.832 1016.22,1020.6 1018.18,1116.96 1020.14,867.94 \n",
       "  1022.1,1021.77 1024.06,1185.69 1026.02,1024.7 1027.98,1192.05 1029.94,335.969 1031.9,897.758 1033.86,969.977 1035.82,795.851 1037.78,991.349 1039.74,985.4 \n",
       "  1041.7,901.188 1043.66,839.176 1045.62,736.092 1047.58,830.305 1049.54,974.63 1051.5,1053.7 1053.46,886.378 1055.42,1152.55 1057.38,1048.71 1059.34,1139.39 \n",
       "  1061.3,847.352 1063.26,633.029 1065.22,1078.69 1067.18,963.935 1069.14,1057.65 1071.1,684.477 1073.06,965.97 1075.02,1082.18 1076.98,940.075 1078.94,1198.09 \n",
       "  1080.9,1358.94 1082.86,646.755 1084.82,1371.41 1086.78,695.777 1088.73,1216.16 1090.69,945.606 1092.65,1224.52 1094.61,1261.29 1096.57,1155.7 1098.53,1027.58 \n",
       "  1100.49,1027.72 1102.45,1358.45 1104.41,876.412 1106.37,1120.63 1108.33,1175.94 1110.29,1010.97 1112.25,957.318 1114.21,751.931 1116.17,716.491 1118.13,975.834 \n",
       "  1120.09,1023.61 1122.05,746.418 1124.01,1188.31 1125.97,1069.22 1127.93,1324.92 1129.89,956.425 1131.85,982.776 1133.81,840.478 1135.77,1084.27 1137.73,880.518 \n",
       "  1139.69,1088.83 1141.65,1326.87 1143.61,448.236 1145.57,875.281 1147.53,512.657 1149.49,981.347 1151.45,1258.83 1153.41,1112.68 1155.37,842.374 1157.33,979.432 \n",
       "  1159.29,1285.44 1161.25,991.508 1163.21,1061.67 1165.17,1024.52 1167.13,1016.19 1169.09,736.895 1171.05,1026.13 1173.01,1209.8 1174.97,994.995 1176.93,720.001 \n",
       "  1178.89,776.798 1180.85,932.227 1182.81,1187.84 1184.77,400.859 1186.73,1335.02 1188.69,1214.95 1190.65,1167.53 1192.61,827.743 1194.56,1069.75 1196.52,1171.14 \n",
       "  1198.48,765.847 1200.44,1011.24 1202.4,983.952 1204.36,686.748 1206.32,877.404 1208.28,903.081 1210.24,942.933 1212.2,1103.77 1214.16,717.187 1216.12,1190.89 \n",
       "  1218.08,980.207 1220.04,644.926 1222,865.519 1223.96,1389.81 1225.92,1310.69 1227.88,909.704 1229.84,1289.39 1231.8,850.217 1233.76,952.512 1235.72,1296.18 \n",
       "  1237.68,509.569 1239.64,465.774 1241.6,1231.49 1243.56,1389.31 1245.52,1090 1247.48,1032.94 1249.44,1161.18 1251.4,1187.48 1253.36,807.865 1255.32,870.544 \n",
       "  1257.28,1292.39 1259.24,782.749 1261.2,631.262 1263.16,644.897 1265.12,990.867 1267.08,1242.37 1269.04,1256.26 1271,737.709 1272.96,1150.32 1274.92,710.155 \n",
       "  1276.88,708.043 1278.84,1308.96 1280.8,768.475 1282.76,1340.33 1284.72,1147.58 1286.68,1076.95 1288.64,1294.54 1290.6,638.765 1292.56,1250.55 1294.52,1011.47 \n",
       "  1296.48,1104.22 1298.43,963.511 1300.39,1299.2 1302.35,845.183 1304.31,1048.63 1306.27,1187.63 1308.23,934.711 1310.19,1094.66 1312.15,1067.34 1314.11,1271.99 \n",
       "  1316.07,1150.16 1318.03,714.699 1319.99,1142.39 1321.95,1282.75 1323.91,959.915 1325.87,877.494 1327.83,989.688 1329.79,1100.37 1331.75,897.416 1333.71,1329.92 \n",
       "  1335.67,764.476 1337.63,979.793 1339.59,1270 1341.55,727.775 1343.51,910.284 1345.47,1307.14 1347.43,845.675 1349.39,720.112 1351.35,1233.77 1353.31,1028.09 \n",
       "  1355.27,617.459 1357.23,766.101 1359.19,596.681 1361.15,1198.48 1363.11,1276 1365.07,1026.03 1367.03,860.106 1368.99,1300.39 1370.95,1173.85 1372.91,1154.97 \n",
       "  1374.87,922.648 1376.83,1166.09 1378.79,1155.59 1380.75,1224.03 1382.71,1246.87 1384.67,758.386 1386.63,1134.6 1388.59,995.96 1390.55,1090.96 1392.51,1237.39 \n",
       "  1394.47,1430.06 1396.43,1285.64 1398.39,1428.99 1400.35,1260.93 1402.31,1176.08 1404.26,1096.66 1406.22,1054.79 1408.18,869.601 1410.14,566.758 1412.1,971.546 \n",
       "  1414.06,1087.78 1416.02,1232.25 1417.98,734.569 1419.94,1091.65 1421.9,1185.93 1423.86,804.163 1425.82,631.375 1427.78,704.806 1429.74,783.985 1431.7,863.212 \n",
       "  1433.66,1211.34 1435.62,886.45 1437.58,717.09 1439.54,1205.04 1441.5,820.949 1443.46,1202.73 1445.42,1062.98 1447.38,1166.92 1449.34,1308.99 1451.3,1136.44 \n",
       "  1453.26,1107.82 1455.22,1145.57 1457.18,1273.75 1459.14,1005.42 1461.1,1208.04 1463.06,692.946 1465.02,1059.53 1466.98,1150.95 1468.94,1198.53 1470.9,860.837 \n",
       "  1472.86,1031.71 1474.82,1079.23 1476.78,1123.11 1478.74,1063.45 1480.7,1156.21 1482.66,1038.94 1484.62,709.766 1486.58,545.404 1488.54,1267.16 1490.5,1258.96 \n",
       "  1492.46,1258.67 1494.42,1108.68 1496.38,903.082 1498.34,878.766 1500.3,1042.34 1502.26,939.086 1504.22,1186.16 1506.18,822.547 1508.14,958.015 1510.09,1320 \n",
       "  1512.05,677.257 1514.01,1228.82 1515.97,1264.21 1517.93,971.687 1519.89,867.535 1521.85,802.949 1523.81,1132.42 1525.77,1220.09 1527.73,1143.49 1529.69,921.068 \n",
       "  1531.65,1127.49 1533.61,1282.53 1535.57,1151.42 1537.53,1233.17 1539.49,844.315 1541.45,1158.79 1543.41,372.821 1545.37,1323.2 1547.33,894.551 1549.29,1110.41 \n",
       "  1551.25,1044.53 1553.21,997.889 1555.17,788.033 1557.13,937.249 1559.09,1230.7 1561.05,883.047 1563.01,1000.58 1564.97,1150.64 1566.93,1049.36 1568.89,1007.78 \n",
       "  1570.85,922.847 1572.81,627.486 1574.77,1083.89 1576.73,1204.97 1578.69,1206.7 1580.65,669.522 1582.61,1133.38 1584.57,552.11 1586.53,919.201 1588.49,1178.12 \n",
       "  1590.45,1026.86 1592.41,958.292 1594.37,1184.99 1596.33,1132.23 1598.29,1145.57 1600.25,758.773 1602.21,863.155 1604.17,947.1 1606.13,1049.17 1608.09,1009.44 \n",
       "  1610.05,1005.74 1612.01,1005.79 1613.96,1086.59 1615.92,721.717 1617.88,1275.93 1619.84,1300.85 1621.8,1173.61 1623.76,977.293 1625.72,1252.74 1627.68,413.934 \n",
       "  1629.64,1203.45 1631.6,1123.18 1633.56,1078.31 1635.52,1236.87 1637.48,838.639 1639.44,1056.35 1641.4,879.979 1643.36,1061.86 1645.32,1304.16 1647.28,1157.56 \n",
       "  1649.24,738.519 1651.2,1028.73 1653.16,1216.57 1655.12,705.76 1657.08,845.457 1659.04,920.898 1661,1126.84 1662.96,904.561 1664.92,787.24 1666.88,87.9763 \n",
       "  1668.84,1415.59 1670.8,981.737 1672.76,958.119 1674.72,1006.15 1676.68,1243.78 1678.64,1048.31 1680.6,1263.41 1682.56,1170.04 1684.52,851.558 1686.48,1182.86 \n",
       "  1688.44,982.361 1690.4,1054.5 1692.36,1221.4 1694.32,1071.64 1696.28,664.485 1698.24,1248.98 1700.2,886.956 1702.16,1117.63 1704.12,828.062 1706.08,1071.55 \n",
       "  1708.04,1197.15 1710,475.402 1711.96,1440.46 1713.92,1074.79 1715.88,738.879 1717.84,1240.03 1719.79,1210.32 1721.75,1067.97 1723.71,1337.12 1725.67,871.11 \n",
       "  1727.63,1135.03 1729.59,923.919 1731.55,886.896 1733.51,762.868 1735.47,430.713 1737.43,1060.7 1739.39,1210.54 1741.35,875.743 1743.31,1014.53 1745.27,1172.54 \n",
       "  1747.23,868.157 1749.19,1291.75 1751.15,725.498 1753.11,1098.93 1755.07,1016.75 1757.03,589.71 1758.99,1137.72 1760.95,924.515 1762.91,1190.93 1764.87,1204.91 \n",
       "  1766.83,1321.1 1768.79,1140.49 1770.75,1289.28 1772.71,801.11 1774.67,1160.33 1776.63,871.273 1778.59,884.124 1780.55,612.271 1782.51,679.703 1784.47,928.204 \n",
       "  1786.43,404.413 1788.39,1123.25 1790.35,921.799 1792.31,1040.15 1794.27,1240.97 1796.23,1060.12 1798.19,1370.68 1800.15,1161.41 1802.11,1113.77 1804.07,1131.94 \n",
       "  1806.03,858.62 1807.99,735.169 1809.95,1445.72 1811.91,1117.31 1813.87,1100.61 1815.83,444.776 1817.79,730.636 1819.75,984.696 1821.71,1112.6 1823.67,903.027 \n",
       "  1825.62,1251.9 1827.58,918.193 1829.54,865.988 1831.5,867.283 1833.46,1181.95 1835.42,1069.86 1837.38,902.02 1839.34,681.641 1841.3,1032.1 1843.26,878.441 \n",
       "  1845.22,1186.32 1847.18,1213.26 1849.14,621.791 1851.1,746.086 1853.06,779.825 1855.02,1174.49 1856.98,883.994 1858.94,992.521 1860.9,1144.39 1862.86,1264.02 \n",
       "  1864.82,1114.07 1866.78,1148.88 1868.74,875.276 1870.7,1080.54 1872.66,1280.89 1874.62,967.683 1876.58,792.611 1878.54,1129.69 1880.5,941.452 1882.46,1207.41 \n",
       "  1884.42,936.742 1886.38,1224.73 1888.34,994.294 1890.3,690.65 1892.26,1055.65 1894.22,868.247 1896.18,635.403 1898.14,583.73 1900.1,1019.04 1902.06,944.321 \n",
       "  1904.02,1013.63 1905.98,467.944 1907.94,1135.18 1909.9,1047.54 1911.86,732.242 1913.82,880.282 1915.78,923.077 1917.74,973.132 1919.7,1135.79 1921.66,941.505 \n",
       "  1923.62,1115.43 1925.58,1333.05 1927.54,951.786 1929.49,657.181 1931.45,970.375 1933.41,1355.11 1935.37,1280.17 1937.33,515.74 1939.29,1192.7 1941.25,1112.78 \n",
       "  1943.21,1072.91 1945.17,1147.35 1947.13,1035.13 1949.09,852.172 1951.05,901.351 1953.01,963.538 1954.97,1078.19 1956.93,802.145 1958.89,1131.89 1960.85,1051.07 \n",
       "  1962.81,1088.67 1964.77,1323.59 1966.73,1243.27 1968.69,1074.69 1970.65,1113.4 1972.61,949.859 1974.57,896.966 1976.53,1118.07 1978.49,671.359 1980.45,1321.32 \n",
       "  1982.41,1424.54 1984.37,724.382 1986.33,1151.52 1988.29,692.167 1990.25,1009.46 1992.21,935.896 1994.17,1001.31 1996.13,1123.04 1998.09,635.365 2000.05,934.347 \n",
       "  2002.01,1072.81 2003.97,825.353 2005.93,718.364 2007.89,839.414 2009.85,1174.13 2011.81,1138.19 2013.77,834.211 2015.73,1010.81 2017.69,1109.12 2019.65,940.311 \n",
       "  2021.61,1225.6 2023.57,1198.76 2025.53,997.984 2027.49,1127.83 2029.45,1217.57 2031.41,1063.2 2033.37,1160.95 2035.32,1092.02 2037.28,1047.97 2039.24,648.823 \n",
       "  2041.2,665.107 2043.16,1273.51 2045.12,1122.5 2047.08,1091.53 2049.04,1141.55 2051,1223.14 2052.96,1001.69 2054.92,620.864 2056.88,526.933 2058.84,905.152 \n",
       "  2060.8,1296.94 2062.76,1155.81 2064.72,1006.35 2066.68,1296.69 2068.64,1288.85 2070.6,1154.43 2072.56,1033.7 2074.52,1003.22 2076.48,822.632 2078.44,870.125 \n",
       "  2080.4,769.877 2082.36,1083.08 2084.32,548.043 2086.28,1177.57 2088.24,824.581 2090.2,1181.1 2092.16,1009.22 2094.12,1244.04 2096.08,1142.38 2098.04,1127.33 \n",
       "  2100,1148.12 2101.96,1095.73 2103.92,946.706 2105.88,913.961 2107.84,784.578 2109.8,1238.02 2111.76,944.139 2113.72,1169.28 2115.68,497.558 2117.64,1186.88 \n",
       "  2119.6,1120.51 2121.56,1035.46 2123.52,1034.06 2125.48,1171.95 2127.44,1301.67 2129.4,1085.95 2131.36,542.252 2133.32,1154.59 2135.28,921.803 2137.24,757.173 \n",
       "  2139.2,936.607 2141.15,833.799 2143.11,436.551 2145.07,843.291 2147.03,704.401 2148.99,898.188 2150.95,1118.63 2152.91,908.953 2154.87,867.808 2156.83,1294.19 \n",
       "  2158.79,1282.35 2160.75,983.56 2162.71,1359.46 2164.67,973.087 2166.63,909.28 2168.59,1179.4 2170.55,840.761 2172.51,866.437 2174.47,1299.05 2176.43,845.647 \n",
       "  2178.39,900.241 2180.35,1078.92 2182.31,1204.48 2184.27,899.315 2186.23,1020.08 2188.19,1084.69 2190.15,1064.49 2192.11,1271.24 2194.07,1111.77 2196.03,808.943 \n",
       "  2197.99,914.678 2199.95,1152.42 2201.91,1137.27 2203.87,934.778 2205.83,706.062 2207.79,1077.61 2209.75,1355.19 2211.71,914.092 2213.67,1037.72 2215.63,964.616 \n",
       "  2217.59,897.992 2219.55,1046.59 2221.51,995.66 2223.47,1212.86 2225.43,1262.65 2227.39,1297.04 2229.35,964.916 2231.31,593.57 2233.27,1243 2235.23,1138.75 \n",
       "  2237.19,827.321 2239.15,701.435 2241.11,1182.97 2243.07,544.814 2245.02,1128.78 2246.98,1179.27 2248.94,645.688 2250.9,1025.36 2252.86,804.268 2254.82,914.59 \n",
       "  2256.78,1212.46 2258.74,1009.08 2260.7,1127.84 2262.66,1114.87 2264.62,1216.81 2266.58,1277.83 2268.54,1213.36 2270.5,663.303 2272.46,1038.21 2274.42,1318.23 \n",
       "  2276.38,714.418 2278.34,839.725 2280.3,1126.43 2282.26,879.34 2284.22,717.943 2286.18,1102.31 2288.14,947.577 2290.1,1186.86 2292.06,740.285 2294.02,940.43 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip770)\" d=\"\n",
       "M2000.56 198.898 L2283.58 198.898 L2283.58 95.2176 L2000.56 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2000.56,198.898 2283.58,198.898 2283.58,95.2176 2000.56,95.2176 2000.56,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip770)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2023.62,147.058 2161.97,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip770)\" d=\"M2198.87 166.745 Q2197.07 171.375 2195.35 172.787 Q2193.64 174.199 2190.77 174.199 L2187.37 174.199 L2187.37 170.634 L2189.87 170.634 Q2191.63 170.634 2192.6 169.8 Q2193.57 168.967 2194.75 165.865 L2195.52 163.921 L2185.03 138.412 L2189.54 138.412 L2197.65 158.689 L2205.75 138.412 L2210.26 138.412 L2198.87 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip770)\" d=\"M2217.55 160.402 L2225.19 160.402 L2225.19 134.037 L2216.88 135.703 L2216.88 131.444 L2225.15 129.778 L2229.82 129.778 L2229.82 160.402 L2237.46 160.402 L2237.46 164.338 L2217.55 164.338 L2217.55 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss1, Flux.params(W1, b1), train_data, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [0.8526601897901432 1.8089781878686866 2.843352512230477 3.783402383418999 4.840248197918984; 4.797194978205234 3.7688514161715436 2.779565643803137 1.7445006592620482 0.808295954025268]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×5 Matrix{Float64}:\n",
       " 0.85266  1.80898  2.84335  3.7834  4.84025\n",
       " 4.79719  3.76885  2.77957  1.7445  0.808296"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 = [1.3049211044422402, 0.9647066212655245]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.3049211044422402\n",
       " 0.9647066212655245"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum(abs, W1 .- W_truth) = 0.2554993407379518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2554993407379518"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show maximum(abs, W1 .- W_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(model_to_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "σ (generic function with 2 methods)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "σ (generic function with 2 methods)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\"></span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
