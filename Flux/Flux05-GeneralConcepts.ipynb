{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\"> Create a 'Scale' layer which takes in inputs and scales the values linearly </span>\n",
    "\n",
    "- Does not perform any transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(1 => 3),                        \u001b[90m# 6 parameters\u001b[39m\n",
       ") "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = Chain( Dense(1=>3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:weight, :bias, :σ)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(typeof(m1.layers[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Matrix{Float32}:\n",
       " -1.0532591\n",
       " -1.0067676\n",
       "  0.01625458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.layers[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float32}:\n",
       " -1.0532591\n",
       " -1.0067676\n",
       "  0.01625458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1( [1] ) #values returned / mapped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scale(3)            \u001b[90m# 6 parameters\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s = Flux.Scale( [0.1, 10, 100] ) #scaling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Chain(\n",
       "    Dense(1 => 3),                      \u001b[90m# 6 parameters\u001b[39m\n",
       "  ),\n",
       "  Scale(3),                             \u001b[90m# 6 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m12 parameters, 360 bytes."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled = Chain( m1 , m1s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       "  -0.10532591342926026\n",
       " -10.067676305770874\n",
       "   1.6254579648375511"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled( [1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scale(3)            \u001b[90m# 6 parameters\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s2 = Flux.Scale( repeat( [0.01] , 3 ) ) #scaling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Chain(\n",
       "    Dense(1 => 3),                      \u001b[90m# 6 parameters\u001b[39m\n",
       "  ),\n",
       "  Scale(3),                             \u001b[90m# 6 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m12 parameters, 360 bytes."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled2 = Chain( m1 , m1s2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " -0.010532591342926025\n",
       " -0.010067676305770875\n",
       "  0.0001625457964837551"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled2( [1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scale(3)            \u001b[90m# 6 parameters\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s3 = Flux.Scale( [1,0,1] ) #scaling layer which operates as a removing a neuron (dimension) component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Chain(\n",
       "    Dense(1 => 3),                      \u001b[90m# 6 parameters\u001b[39m\n",
       "  ),\n",
       "  Scale(3),                             \u001b[90m# 6 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m12 parameters, 360 bytes."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled3 = Chain( m1 , m1s3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float32}:\n",
       " -1.0532591\n",
       "  0.0\n",
       "  0.01625458"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1scaled3( [1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\"> Convolution Models </span>\n",
    "\n",
    "- Images (2D data) fed into CNN layers require the <u>W-H-C-N</u> order, which is Width-Height-ChannelNum-BatchSize. Eg if we have images width=28, height=28, 3 channels (R-G-B) and there are 100 of these images in the batch, the size of that data structure fed to the CNN layer is (28,28,3,100). If the images were monochromatic (gray scale) then the size would be (28,28,1,100). \n",
    "- Data can be 1D, for 1D convolutions, on time series or mono audio data, so that the format becomes W-C-N, eg. if we have 100 audio samples in one channel (mono) and each sample has 250 dimensions the size is, (250,1,1). If the data was stereo (2 channel) then the size would be (250,2,1)\n",
    "- If the data was 3D (like data from a magnetic scan), it could look like this (28,28,28,1,100) where the last 2 dimensions are the channel number and batch size. \n",
    "- The Convolutional (CNN) layer takes in a <u>filter size</u> to scan over the data.\n",
    "- The Convolutional (CNN) layer takes in the <u>channel size mapping</u>, which does a transformation from the input channel number to the output channel number. \n",
    "- Key parameter values are <u>stride</u>, <u>padding</u>, <u>dilation</u>\n",
    "- Padding specifies the number of pixels (elements) placed on the borders (boundaries of the data in each dimension). A single value (integer) for uniform padding around the data array, or if there 3 spatial dimensions a tuple of 3 integers is needed to specify the padding if not uniform. You can supply a 2x3 = 6 dimension tuple to padding to specify the padding for each boundary specifically. **note padding will change the size of the image after the application of the cnn filter**\n",
    "- <u>SamePad()</u> is a useful utility function so that it applies the necessary padding in order for the data dimensions to stay the same after the cnn filter application; that is a 28x28 image with SamePad() applied will still become 28x28 after exiting that layer and becoming input into the subsequent layer.\n",
    "\n",
    "\n",
    "#### convolution gifs from [ Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> No padding, no strides </span>\n",
    "\n",
    "![image info](./demoPics/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); #batch of monochrome images\n",
    "size( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv((5, 5), 1 => 1)  \u001b[90m# 26 parameters\u001b[39m"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer = Conv( (5,5) , 1 => 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 1, 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_output = cnn_layer(x)\n",
    "size( cnn_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size( x ) == size( cnn_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv((5, 5), 1 => 1, pad=2)  \u001b[90m# 26 parameters\u001b[39m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer2 = Conv( (5,5) , 1 => 1 , pad = 2 ) #apply some padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_output2 = cnn_layer2( x )\n",
    "size( cnn_output2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size( x ) == size( cnn_output2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\"> try SamePad() </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv((5, 5), 1 => 1, pad=2)  \u001b[90m# 26 parameters\u001b[39m"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer3 = Conv( (5,5) , 1 => 1 , pad = SamePad() ) #apply some padding using the SamePad() function helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_output3 = cnn_layer3( x )\n",
    "size( cnn_output3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size( x ) == size( cnn_output3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\"> What happens to the size on repeated applications of a filter </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); #batch of monochrome images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((5, 5), 1 => 3),                 \u001b[90m# 78 parameters\u001b[39m\n",
       "  Conv((5, 5), 3 => 5),                 \u001b[90m# 380 parameters\u001b[39m\n",
       "  Conv((5, 5), 5 => 8),                 \u001b[90m# 1_008 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m1_466 parameters, 6.781 KiB."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer = Chain( Conv( (5,5) , 1=>3 ) , Conv( (5,5) , 3=>5 ) , Conv( (5,5) , 5=>8 ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 88, 8, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_output = cnn_layer( x )\n",
    "size( cnn_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((5, 5), 1 => 3, pad=2),          \u001b[90m# 78 parameters\u001b[39m\n",
       "  Conv((5, 5), 3 => 5, pad=2),          \u001b[90m# 380 parameters\u001b[39m\n",
       "  Conv((5, 5), 5 => 8, pad=2),          \u001b[90m# 1_008 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m1_466 parameters, 6.781 KiB."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer_same_pad = Chain( Conv((5,5),1=>3,pad=SamePad()),Conv((5,5),3=>5,pad=SamePad()),Conv((5,5),5=>8,pad=SamePad()) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 8, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_layer_same_pad = cnn_layer_same_pad( x )\n",
    "size( cnn_layer_same_pad )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Example like the gif above </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 4, 4, 1, 10); #batch of monochrome images\n",
    "cnn_layer = Conv( (3,3) , 1 => 1 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Add arbitrary padding (zeros) </span>\n",
    "\n",
    "![image info](./demoPics/arbitrary_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12×12×1×1 Array{Float32, 4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0       …   0.0        0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0           0.0        0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0           0.0        0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  -0.249219  -0.262202  -0.196942     -0.0217773  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.25504    0.980319   0.295236     -0.109904   0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.784704   0.342678  -0.433007  …  -0.217018   0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.401285   0.048833  -0.18198      -0.444861   0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.749026   0.830429   0.137994     -0.24143    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.382977  -0.223528  -0.338113     -0.3098     0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0           0.0        0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0       …   0.0        0.0  0.0  0.0\n",
       " 0.0  0.0  0.0   0.0        0.0        0.0           0.0        0.0  0.0  0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 4, 4, 1, 1); #batch of monochrome images\n",
    "cnn_layer = Conv( (3,3) , 1 => 1 , pad = 5)\n",
    "println( cnn_layer( x ) |> size )\n",
    "cnn_layer( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×12×1×1 Array{Float32, 4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0  -0.579736    0.527731  …  0.493209  0.296352  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  -0.0546827  -0.698075     0.397847  0.345251  0.0  0.0  0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 4, 4, 1, 1); \n",
    "cnn_layer = Conv( (3,3) , 1 => 1 , pad = (0,5) ) #non-uniform padding\n",
    "println( cnn_layer( x ) |> size )\n",
    "cnn_layer( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> On 1D data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 1, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 1, 1); #100elements, 1 channel, 10 samples in the batch \n",
    "cnn_layer = Conv( (4,) , 1 => 1 ) #4 element filter\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 1, 1); #100elements, 1 channel, 10 samples in the batch \n",
    "cnn_layer = Conv( (4,) , 1 => 1 , pad = SamePad() ) #4 element filter\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Now apply 'Strides' </span>\n",
    "![image info](./demoPics/no_padding_strides.gif)\n",
    "\n",
    "(no padding but with strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 1, 1); #100elements, 1 channel, 10 samples in the batch \n",
    "cnn_layer = Conv( (4,) , 1 => 1 , stride=5 ) #4 element filter\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 1, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 1, 1); #100elements, 1 channel, 10 samples in the batch \n",
    "cnn_layer = Conv( (4,) , 1 => 1 , stride=1 ) \n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 3, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 50, 50, 2, 10); #batch of monochrome images\n",
    "cnn_layer = Conv( (3,3) , 2 => 3 , stride = 5 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Padding and Strides </span>\n",
    "\n",
    "![image info](./demoPics/padding_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41, 3, 10)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 3, 10); #batch of monochrome images\n",
    "cnn_layer = Conv( (4,4) , 3 => 3 , pad=4 , stride = 5 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Dilation, adds element skipping between element of the filter </span>\n",
    "\n",
    "![image info](./demoPics/dilation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197, 3, 10)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 3, 10); \n",
    "cnn_layer = Conv( (4,4) , 3 => 3 , dilation = 1 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 194, 3, 10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 3, 10); \n",
    "cnn_layer = Conv( (4,4) , 3 => 3 , dilation = 2 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 3, 10); \n",
    "cnn_layer = Conv( (5,5) , 3 => 3 , pad = 2 , dilation=1 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 188, 1, 10)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 1, 10); \n",
    "cnn_layer = Conv( (5,5) , 1 => 1 , pad = 2 , dilation=4 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 1, 10)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 200, 200, 1, 10); \n",
    "cnn_layer = Conv( (5,5) , 1 => 1 , pad = SamePad() , dilation=4 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\"> Transposed convolutional  </span>\n",
    "\n",
    "- Transposed convolutional layers 'upsample' the data, so that the output feature map goes from 'low' resolution to 'high' resolution.\n",
    "- Previously the operations would 'downsample' that reduces resolution.\n",
    "- Increases the size of the output\n",
    "- Takes each kernel element and projects onto the surroundings to create a patch\n",
    "\n",
    "![image info](./demoPics/no_padding_no_strides_transposed.gif)\n",
    "\n",
    "(transposed convolution, no padding no strides)\n",
    "\n",
    "![image info](./demoPics/full_padding_no_strides_transposed.gif)\n",
    "\n",
    "(transposed convolution, full padding no strides)\n",
    "\n",
    "![image info](./demoPics/padding_strides_transposed.gif)\n",
    "\n",
    "(transposed convolution, padding no strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 1, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 1, 10); \n",
    "cnn_layer = ConvTranspose( (5,5) , 1 => 1  )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 1, 10); \n",
    "cnn_layer = ConvTranspose( (5,5) , 1 => 1 , pad=6 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21, 1, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 1, 10); \n",
    "cnn_layer = ConvTranspose( (5,5) , 1 => 1 , pad=1 , stride=2 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 1, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 1, 10); \n",
    "cnn_layer = ConvTranspose( (5,5) , 1 => 1 , pad=SamePad() , stride=2 )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40×40×1×1 Array{Float32, 4}:\n",
       "[:, :, 1, 1] =\n",
       " -0.0446279     0.00479112    0.0992612   …   0.12348     -0.149842\n",
       " -0.0602849    -0.0472154     0.186933        0.232544     0.186137\n",
       "  0.186731      0.11041       0.114736        0.14273     -0.0278084\n",
       " -0.0270291     0.0811776    -0.0489352      -0.18712     -0.113562\n",
       " -0.00543167    0.000583127   0.0120811       0.133592    -0.162113\n",
       " -0.00733727   -0.00574659    0.0227516   …   0.251587     0.201381\n",
       "  0.022727      0.0134381     0.0139645       0.154419    -0.0300857\n",
       " -0.242599      0.226335     -0.155518       -0.190078    -0.13336\n",
       " -0.0638132     0.00685079    0.141933        0.13292     -0.161297\n",
       " -0.0862009    -0.067513      0.267295        0.250321     0.200367\n",
       "  0.267005      0.157875      0.16406     …   0.153641    -0.0299342\n",
       " -0.20779       0.269063     -0.175681       -0.141707    -0.172945\n",
       " -0.0524018     0.0056257     0.116552        0.0877207   -0.106448\n",
       "  ⋮                                       ⋱               \n",
       " -0.0365235     0.00392105    0.0812353       0.00743218  -0.0090189\n",
       " -0.0493371    -0.0386411     0.152986        0.0139966    0.0112035\n",
       "  0.15282       0.0903598     0.0938996   …   0.00859083  -0.00167376\n",
       " -0.144644      0.177258     -0.116623       -0.00853578  -0.00915033\n",
       " -0.0367784     0.00394842    0.0818022       0.00547992  -0.00664984\n",
       " -0.0496814    -0.0389108     0.154054        0.01032      0.00826058\n",
       "  0.153887      0.0909904     0.0945549       0.00633422  -0.00123411\n",
       " -0.0243445     0.0687713    -0.0416214   …  -0.0404275    0.0222336\n",
       " -0.00502242    0.000539192   0.0111708       0.0360976   -0.0438042\n",
       " -0.00678445   -0.00531362    0.0210374       0.0679807    0.0544145\n",
       "  0.0210146     0.0124256     0.0129123       0.0417251   -0.00812936\n",
       " -0.000725458   0.00704055   -0.00405948     -0.0131179   -0.0685036"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 1, 1); \n",
    "cnn_layer = ConvTranspose( (5,5) , 1 => 1 , pad=SamePad() , stride=4 )\n",
    "cnn_layer( x ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\"> Depthwise Convolutional Layers apply kernels to each channel separately so that the kernel does not span all channels </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 5, 10)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 10, 10, 5, 10); \n",
    "cnn_layer = DepthwiseConv( (5,5) , 5 => 5 , pad=SamePad() )\n",
    "cnn_layer( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Common layers often used 'after' a CNN layer </span>\n",
    "\n",
    "- they reduce the size of the output, and do not have parameters to train\n",
    "- MaxPool, takes the maximum element in the region, and the corresponding 'MeanPool' exists\n",
    "- Adaptive Max Pool, this takes in a tuple for the size of the data desired for each channel and batch size and finds for you the MaxPool size for the target output size needed. (equivalently there is the AdaptiveMeanPool)\n",
    "\n",
    "- GlobalMaxPool produces a single value for each of the channels and each of the batch samples (also GlobalMeanPool is there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19, 2, 10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); \n",
    "m = Chain( Conv( (5,5) , 1 => 2 ) , MaxPool((5,5)) )\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 2, 10)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); \n",
    "m = Chain( Conv( (5,5) , 1 => 2 , pad=SamePad() ) , MaxPool((5,5)) )\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 2, 10)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); \n",
    "m = Chain( Conv( (5,5) , 1 => 2  ) , MaxPool( (5,5), pad=SamePad() ) )\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 2, 10)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); \n",
    "m = Chain( Conv( (5,5) , 1 => 2  ) , AdaptiveMaxPool( (40,40) ) ) #we want a 40x40 output from MaxPool\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 10)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 1, 10); \n",
    "m = Chain( Conv( (5,5) , 1 => 3  ) , GlobalMaxPool() ) #we want a 40x40 output from MaxPool\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Upsampling </span>\n",
    "\n",
    "- These do the opposite of pooling. Instead of a transposed convolution these layers 'upsample' by increasing the resolution from the perspective of further interpolating across the domain in the statistical sense. \n",
    "- There are different methods for doing so, such as the bilinear and nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 2, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 2, 10); \n",
    "m = Upsample( :nearest, size= (200,200) )\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 2, 10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(Float32, 100, 100, 2, 10); \n",
    "m = Upsample( :bilinear, scale=4 )\n",
    "m( x ) |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important function utilities ; Flux.flatten    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![image info](./demoPics/arbitrary_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<span style=\"color:orange\">  </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
