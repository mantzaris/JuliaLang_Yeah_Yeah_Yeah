{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Recurrent Models with FluxML</span>\n",
    "\n",
    "#### <span style=\"color:orange\"> Flux does offer out of the box a set of recurrence functionalities in specific layers. Remember that recurrent models can come across as being more complicated than necessary. In general we are still dealing with the same type of funcational relationship, $\\hat{y} = f(X_i) = f_{rnn}(X_t)$ where previously y_hat was either a single dimension or multiple dimensions, here $y_{hat} = [y_t , h_t]$ where $h_t$ is an input into the new time point (memory carry on) so that we have $X_t = [ x_t , h_{t-1}]$. The dependency can be seen as $\\hat{y}_t = f(x_t,h_{t-1}), h_t = g(h_{t-1},x_t)$ </span>\n",
    "\n",
    "- This basic recurrence relationship says that at each point we take the $h_{t-1}$ from the previous time step 't-1', we also use the current inputs at time t, $x_t$ and then produce an output which is has 2 components, $y_t$ and $h_t$ (where $h_t$ feeds into $t+1$). If we focus on a single time point, we are still doing the functional mapping that we had before with the chain of Dense layers.\n",
    "\n",
    "- The below image [link source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2Fswlh%2Fintroduction-to-recurrent-neural-networks-rnns-347903dd8d81&psig=AOvVaw3xmMdMdDizNUUWXy021QUO&ust=1673451409556000&source=images&cd=vfe&ved=0CBAQjhxqFwoTCOCStLiqvfwCFQAAAAAdAAAAABA_) shows how this looks in a model diagram for **seq-to-seq** (**many to many**)\n",
    "\n",
    "![rnn](./rnn1.png)\n",
    "\n",
    "- also The below image [link source](https://www.ibm.com/topics/recurrent-neural-networks) shows how this looks\n",
    "\n",
    "![rnn](./rnn2.jpeg)\n",
    "\n",
    "----------------\n",
    "\n",
    "#### <span style=\"color:orange\"> $W_h$ is the weight matrix (tranformation) on the 'hidden inputs' $h_{t-1}$ that come from the previous unit's 'hidden' output, $W_x$ is the weight matrix (transformation) upon the inputs at the current time $x_t$. $W_y$ is the transformation weight matrix applied to the 'current' hidden value produced from the cell that after a non-linear transformation (activation function) produces the output $\\hat{y}_t$. Training involves learning the values of the weights/parameters for these matrices.</span>\n",
    "\n",
    "### <span style=\"color:orange\"> $h_t = tahn(b_h + W_h^t h_{t-1} + W_x^t x_t)$ </span>\n",
    "### <span style=\"color:orange\"> $\\hat{y}_t = softmax(b_y + W_{y}^{t} h_t)$ </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
      " \u001b[90m [587475ba] \u001b[39mFlux v0.13.11\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.status(\"Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Zygote\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32[0.69022447, -0.8096581, 0.20285046, 0.9096218, 0.98366106]\n"
     ]
    }
   ],
   "source": [
    "#example of usage of the RNN unit\n",
    "h_dim = 5 #hidden dimension\n",
    "x_dim = 2 #input dimension at time t\n",
    "y_dim = 1 #the output dimension that 'we' see\n",
    "\n",
    "rnn_tmp = RNN( x_dim , h_dim ) #produces the cell\n",
    "x_t1 = Float32.( [1,2] ) #some arbitrary input data\n",
    "println( rnn_tmp( x_t1 ) ) #print the output h_t1 from the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> It is key to know that this cell is different from the Dense layers in that it maintains the state between executions since it is **stateful**. This means it holds the state via a closure inside the function reference</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32[0.62560636, -0.6375957, -0.70103127, 0.98585385, 0.9766354]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Float32}}:\n",
       " [0.17537902, -0.8766658, -0.039731663, 0.98278844, 0.98923373]\n",
       " [0.56768286, -0.4575832, -0.54748905, 0.984952, 0.97577643]\n",
       " [0.2968465, -0.87031263, -0.035429336, 0.9775933, 0.98903]\n",
       " [0.5591236, -0.5247114, -0.5636416, 0.9855273, 0.9769787]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_t1 = Float32.( [1,2] ) #some arbitrary input data\n",
    "println( rnn_tmp( x_t1 ) ) #print the output h_t1 from the cell\n",
    "#print multiple times to see the changes\n",
    "display( [ rnn_tmp( x_t1 ) for _ in 1:4 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Since the RNN unit maintains and handles the state between subsequent uses we can abstractly use it in the ML pipeline as we used the Dense layer. From above notice that we produced hidden representation responses from inputs, but not the predictions $\\hat{y}$ since those are done separately. </span>\n",
    "\n",
    "### <span style=\"color:orange\"> The RNN function implements $h_t = tahn(b_h + W_h^t h_{t-1} + W_x^t x_t)$ but $\\hat{y}_t = softmax(b_y + W_{y}^{t} h_t)$ is not. The $W_{y}$ matrix is not provided by the RNN layer and must be supplied by the user. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Recur(\n",
       "    RNNCell(2 => 5, tanh),              \u001b[90m# 45 parameters\u001b[39m\n",
       "  ),\n",
       "  Dense(5 => 1),                        \u001b[90m# 6 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: 6 trainable arrays, \u001b[39m51 parameters,\n",
       "\u001b[90m          # plus 1 non-trainable, 5 parameters, summarysize \u001b[39m580 bytes."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we feed the model with 'x_dim' data, it produces a hidden vector 'h_dim' and outputs a 'y_dim' vector at each time\n",
    "rnn_model1 = Chain( RNN( x_dim => h_dim ) , Dense( h_dim => y_dim ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float32}:\n",
       " 0.49528342"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try out the model\n",
    "rnn_model1( x_t1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Float32}}:\n",
       " [0.34422493]\n",
       " [0.24739702]\n",
       " [0.27857256]\n",
       " [0.29889977]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ rnn_model1( x_t1 ) for _ in 1:4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float32}}:\n",
       " [-0.045894455]\n",
       " [-0.1903576]\n",
       " [0.31945586]\n",
       " [0.26773375]\n",
       " [-0.09483429]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model with hypothetical data\n",
    "x_length = 5\n",
    "#generate some random data as inputs, to be treated as a sequence\n",
    "x_seq = [ rand( Float32 , x_dim ) for i = 1:x_length ] #sequence data\n",
    "[ rnn_model1( xt ) for xt in x_seq ] #predicted y_t data from the RNN\n",
    "#this is <sequence to sequence> <many to many>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.codeproject.com%2FArticles%2F3993967%2FApplying-Long-Short-Term-Memory-for-Video-Classifi&psig=AOvVaw3aJjMa8pFFZ1i53Lk2C-gE&ust=1673466988547000&source=images&cd=vfe&ved=0CBAQjhxqFwoTCNjijr7kvfwCFQAAAAAdAAAAABA4)\n",
    "\n",
    "![rnn](./rnnTypes.jpg)\n",
    "\n",
    "#### Let's consider the <u>**sequence to one**</u> (seq-to-one) now\n",
    "\n",
    "#### Many-to-One Sequence Problems. In many-to-one sequence problems, we have a sequence of data as input, and we have to predict a single output. Sentiment analysis or text classification is one such use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=Float32[0.45206535] x=Vector{Float32}[[0.6127688, 0.64463097], [0.5063315, 0.51324946], [0.42225707, 0.5557735]]\n",
      "Float32[0.0061154924]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19887127f0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#loss function for 3-to-1, a sequence of 3 inputs for a single output\n",
    "#this can be used in the training scheme as before\n",
    "function loss_3_to_1( x , y ) #assume feature data has 3 samples\n",
    "    rnn_model1( x[1] ) # ignores the output but updates the hidden states\n",
    "    rnn_model1( x[2] ) # ignores the output but updates the hidden states again\n",
    "    y_hat = rnn_model1( x[3] )\n",
    "    println( y_hat )\n",
    "    Flux.mse( y_hat , y )\n",
    "end\n",
    "\n",
    "y = rand( Float32 , y_dim ) #target data\n",
    "x = [ rand(Float32, x_dim ) for i=1:3 ] #sequence of 3 x values\n",
    "println(\"y=\",y,\" x=\",x)\n",
    "loss_3_to_1( x , y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32[0.17869426]\n",
      "loss = 0.00947706\n",
      "Float32[0.06198415]\n",
      "loss = 0.39413822\n",
      "Float32[0.02115184]\n",
      "loss = 0.10041485\n",
      "Float32[-0.034993455]\n",
      "loss = 0.06462539\n",
      "Float32[-0.106653616]\n",
      "loss = 0.7453846\n",
      "Float32[0.09934425]\n",
      "loss = 0.017711176\n",
      "Float32[0.4105385]\n",
      "loss = 0.13272479\n",
      "Float32[0.50154114]\n",
      "loss = 0.0025325792\n",
      "Float32[0.13664865]\n",
      "loss = 0.6564374\n",
      "Float32[0.16808915]\n",
      "loss = 0.024807723\n"
     ]
    }
   ],
   "source": [
    "#produce a hypothetical sequence of data points in x_dim dimensions\n",
    "#with y_dim data and pass that to the loss\n",
    "x_data = [ [rand(Float32,x_dim) for i=1:3] for j=1:10 ]\n",
    "y_data = [ rand( Float32 , y_dim ) for j=1:10 ]\n",
    "data = zip( x_data , y_data ) #pack the data into pairs\n",
    "\n",
    "for (x_tmp,y_tmp) in data\n",
    "    println( \"loss = \" , loss_3_to_1( x_tmp , y_tmp ) )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\"> If you need to use the RNN and not have it dependent upon the previous state (eg. independent sentences), then you can use the **Flux.reset!(rnn_model)** command so the previous history variables are removed </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_3_to_1_reset (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add a reset so that each sentence is taken independently\n",
    "function loss_3_to_1_reset( x , y ) #assume feature data has 3 samples\n",
    "    Flux.reset!( rnn_model1 ) #reset the model from previous sentences\n",
    "    rnn_model1( x[1] ) # ignores the output but updates the hidden states\n",
    "    rnn_model1( x[2] ) # ignores the output but updates the hidden states again\n",
    "    y_hat = rnn_model1( x[3] )\n",
    "    Flux.mse( y_hat , y )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">One to many RNN</span>\n",
    "\n",
    "- Take a single X input and then output a series of Y outputs\n",
    "- Some architectures will require a bit of manual construction\n",
    "- One-to-many sequence problems are sequence problems where the input data has one time-step, and the output contains a vector of multiple values or multiple time-steps. Thus, we have a single input and a sequence of outputs.\n",
    "A typical example is image captioning, where the description of an image is generated. Or music generation from a description.\n",
    "\n",
    "[link source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fdiscuss.pytorch.org%2Ft%2Fone-to-many-lstm%2F96932&psig=AOvVaw0Ha6GO6T8UyXiD-It1widc&ust=1673625753189000&source=images&cd=vfe&ved=0CBAQjhxqFwoTCMie7vWzwvwCFQAAAAAdAAAAABBa)\n",
    "\n",
    "![rnn](./rnn1toMany.jpeg)\n",
    "\n",
    "\n",
    "### In this case we must make sure the 'hidden' state values are cycled as inputs and the previous unit definitions abstract away that hidden unit productions. The units must return the states (hidden) so be passed as subsequent inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNCell(2 => 2, tanh)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn1 = Flux.RNNCell(2, 2)\n",
    "rnn2 = Flux.RNNCell(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[-0.9614495, 0.9461154], Float32[-0.9614495, 0.9461154])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, y = rnn1( Float32.([2,2]) , Float32.([1,2])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  RNNCell(2 => 2, tanh),                \u001b[90m# 12 parameters\u001b[39m\n",
       "  RNNCell(2 => 2, tanh),                \u001b[90m# 12 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 8 arrays, \u001b[39m24 parameters, 608 bytes."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(rnn1, rnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <span style=\"color:orange\">write a function and make a function for the gradient of the function</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
