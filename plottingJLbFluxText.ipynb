{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, logitcrossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition\n",
    "using Parameters: @with_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter arguments \n",
    "@with_kw mutable struct Args\n",
    "    lr::Float64 = 1e-2\t# Learning rate\n",
    "    seqlen::Int = 50\t# Length of batch sequences\n",
    "    nbatch::Int = 50\t# Number of batches text is divided into\n",
    "    throttle::Int = 30\t# Throttle timeout\n",
    "    epochs::Int = 2     # Number of Epochs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_model (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function getdata(args)\n",
    "    # Download the data if not downloaded as 'input.txt'\n",
    "    isfile(\"input.txt\") ||\n",
    "        download(\"https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\",\"input.txt\")\n",
    "\n",
    "    text = collect(String(read(\"input.txt\")))\n",
    "    \n",
    "    # an array of all unique characters\n",
    "    alphabet = [unique(text)..., '_']\n",
    "    \n",
    "    text = map(ch -> onehot(ch, alphabet), text)\n",
    "    stop = onehot('_', alphabet)\n",
    "\n",
    "    N = length(alphabet)\n",
    "    \n",
    "    # Partitioning the data as sequence of batches, which are then collected as array of batches\n",
    "    Xs = collect(partition(batchseq(chunk(text, args.nbatch), stop), args.seqlen))\n",
    "    Ys = collect(partition(batchseq(chunk(text[2:end], args.nbatch), stop), args.seqlen))\n",
    "\n",
    "    return Xs, Ys, N, alphabet\n",
    "end\n",
    "\n",
    "# Function to construct model\n",
    "function build_model(N)\n",
    "    return Chain(\n",
    "            LSTM(N, 128),\n",
    "            LSTM(128, 128),\n",
    "            Dense(128, N))\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    # Initialize the parameters\n",
    "    args = Args(; kws...)\n",
    "    \n",
    "    # Get Data\n",
    "    Xs, Ys, N, alphabet = getdata(args)\n",
    "\n",
    "    # Constructing Model\n",
    "    m = build_model(N)\n",
    "\n",
    "    function loss(xs, ys)\n",
    "        Flux.reset!(m)\n",
    "        return sum(logitcrossentropy.([m(x) for x in xs], ys))\n",
    "    end\n",
    "    \n",
    "    ## Training\n",
    "    opt = ADAM(args.lr)\n",
    "    tx, ty = (Xs[5], Ys[5])\n",
    "    evalcb = () -> @show loss(tx, ty)\n",
    "\n",
    "    @info \"Start Training, total $(args.epochs) epochs\"\n",
    "    for epoch = 1:args.epochs\n",
    "        @info \"Epoch $(epoch) / $(args.epochs)\"\n",
    "        Flux.train!(loss, params(m), zip(Xs, Ys), opt, cb = throttle(evalcb, args.throttle))\n",
    "    end\n",
    "    return m, alphabet\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Start Training, total 2 epochs\n",
      "└ @ Main In[4]:21\n",
      "┌ Info: Epoch 1 / 2\n",
      "└ @ Main In[4]:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(tx, ty) = 189.17505f0 (tracked)\n",
      "loss(tx, ty) = 120.48378f0 (tracked)\n",
      "loss(tx, ty) = 108.22152f0 (tracked)\n",
      "loss(tx, ty) = 98.51938f0 (tracked)\n",
      "loss(tx, ty) = 92.5108f0 (tracked)\n",
      "loss(tx, ty) = 88.835304f0 (tracked)\n",
      "loss(tx, ty) = 86.45531f0 (tracked)\n",
      "loss(tx, ty) = 85.08198f0 (tracked)\n",
      "loss(tx, ty) = 83.088425f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "function sample_data(m, alphabet, len; seed=\"\")\n",
    "    m = cpu(m)\n",
    "    Flux.reset!(m)\n",
    "    buf = IOBuffer()\n",
    "    if seed == \"\"\n",
    "        seed = string(rand(alphabet))\n",
    "    end\n",
    "    write(buf, seed)\n",
    "    c = wsample(alphabet, softmax([m(onehot(c, alphabet)) for c in collect(seed)][end]))\n",
    "    for i = 1:len\n",
    "        write(buf, c)\n",
    "        c = wsample(alphabet, softmax(m(onehot(c, alphabet))))\n",
    "    end\n",
    "    return String(take!(buf))\n",
    "end\n",
    "\n",
    "cd(@__DIR__)\n",
    "m, alphabet = train()\n",
    "sample_data(m, alphabet, 1000) |> println\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
